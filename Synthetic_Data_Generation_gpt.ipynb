{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Synthetic Data Generation with Gpt",
   "id": "ebaeedf11805ed18"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-03T07:50:35.615533Z",
     "start_time": "2025-06-03T07:50:34.421752Z"
    }
   },
   "source": [
    "import os\n",
    "from utils.AzureAdapter import AzureAdapter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"AZURE_API_KEY\")\n",
    "api_endpoint = os.getenv(\"AZURE_API_ENDPOINT\")\n",
    "api_version = os.getenv(\"AZURE_API_VERSION\")\n",
    "deployment_name = \"gpt-4o\"\n",
    "\n",
    "llm = AzureAdapter(api_key=api_key, api_endpoint=api_endpoint, api_version=api_version)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T08:02:31.281646Z",
     "start_time": "2025-06-03T08:02:31.274869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from random import randint\n",
    "from utils.save_and_load_json import save_json\n",
    "\n",
    "def parse_and_save(llm_response, folder_path=\"\", save_data=True):\n",
    "    seed = int(time.time())\n",
    "\n",
    "    # Parse the response from the llm\n",
    "    data = json.loads(llm_response)\n",
    "\n",
    "    # Add sel_idx and id\n",
    "    if type(data) == dict and 'puzzles' in data.keys():\n",
    "        data = data['puzzles']\n",
    "\n",
    "    if type(data) == dict:\n",
    "        data = [data]\n",
    "\n",
    "    # Save each puzzle as own json\n",
    "    for puzzle in data:\n",
    "        rand =  randint(0, 1000000)\n",
    "        puzzle['id'] = rand\n",
    "        puzzle['sel_idx'] = rand\n",
    "        if save_data:\n",
    "            save_json(data=puzzle, file_path=f'{folder_path}/{seed}_{rand}.json')\n",
    "\n",
    "    print((type(data), len(data)))\n",
    "    return data\n",
    "\n",
    "def has_enough_json_files(folder_path, target_count):\n",
    "    \"\"\"\n",
    "    Check if a folder contains at least the target number of JSON files.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(folder_path):\n",
    "        raise ValueError(f\"The folder path '{folder_path}' does not exist or is not a directory\")\n",
    "\n",
    "    json_count = sum(1 for file in os.listdir(folder_path) if file.lower().endswith('.json'))\n",
    "\n",
    "    return json_count >= target_count"
   ],
   "id": "85cc18c9c1c1f7c4",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Generating puzzles with one llm call",
   "id": "bb335258a96e709d"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-03T08:10:02.204334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from prompts.prompts import entire_puzzle_generation_prompt\n",
    "\n",
    "folder_path = './data/synthetic/gpt_one_call'\n",
    "\n",
    "while not has_enough_json_files(folder_path, target_count=250):\n",
    "    prompt = 'Generate generate 10 new puzzles'\n",
    "    try:\n",
    "        res = llm.call_model(prompt=prompt, system_prompt=entire_puzzle_generation_prompt, deployment_name=deployment_name)\n",
    "        data = parse_and_save(folder_path=folder_path, llm_response=res)\n",
    "        print(f'{len(data)} successfully generated')\n",
    "    except Exception as ex:\n",
    "        print('Skipping generation!')\n",
    "        print(ex)"
   ],
   "id": "fb85557da2051766",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'list'>, 1)\n",
      "1 successfully generated\n",
      "(<class 'list'>, 2)\n",
      "2 successfully generated\n",
      "(<class 'list'>, 1)\n",
      "1 successfully generated\n",
      "(<class 'list'>, 1)\n",
      "1 successfully generated\n",
      "(<class 'list'>, 3)\n",
      "3 successfully generated\n",
      "(<class 'list'>, 2)\n",
      "2 successfully generated\n",
      "(<class 'list'>, 1)\n",
      "1 successfully generated\n",
      "(<class 'list'>, 2)\n",
      "2 successfully generated\n",
      "Skipping generation!\n",
      "Unterminated string starting at: line 234 column 11 (char 14313)\n",
      "(<class 'list'>, 1)\n",
      "1 successfully generated\n",
      "(<class 'list'>, 1)\n",
      "1 successfully generated\n",
      "Skipping generation!\n",
      "Unterminated string starting at: line 254 column 23 (char 15211)\n",
      "(<class 'list'>, 1)\n",
      "1 successfully generated\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Creating Puzzles in two llm calls",
   "id": "b1678ffc89fbddd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T08:00:48.162064Z",
     "start_time": "2025-06-03T08:00:02.294372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from prompts.prompts import question_generation_prompt, solution_generation_prompt\n",
    "\n",
    "n = 3\n",
    "folder_path = '/data/synthetic/gpt_two_calls'\n",
    "questions = None\n",
    "retry = False\n",
    "\n",
    "while not has_enough_json_files(folder_path=folder_path, target_count=25):\n",
    "    if not retry:\n",
    "        try:\n",
    "            # Create puzzle questions\n",
    "            prompt_questions = \"Generate generate {} new puzzle questions\".format(n)\n",
    "            res_questions = llm.call_model(prompt=prompt_questions, system_prompt=question_generation_prompt, deployment_name=deployment_name)\n",
    "            questions = parse_and_save(llm_response=res_questions, save_data=False)\n",
    "        except Exception as ex:\n",
    "            print('Skipping generation!')\n",
    "            print(ex)\n",
    "            questions = None\n",
    "\n",
    "    if questions:\n",
    "        try:\n",
    "            retry = False\n",
    "            prompt_solutions = \"Solve all {} logical puzzles:\\n {}\".format(n, questions)\n",
    "            res_solutions = llm.call_model(prompt=prompt_solutions, system_prompt=solution_generation_prompt, deployment_name=deployment_name)\n",
    "            solutions = parse_and_save(folder_path=folder_path, llm_response=res_solutions, save_data=True)\n",
    "        except Exception as ex:\n",
    "            print('Retrying generation!')\n",
    "            retry = True"
   ],
   "id": "38c726a826ebc414",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'list'>, 1)\n",
      "(<class 'list'>, 1)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Puzzle verification\n",
    "\n",
    "##### Duplicates\n",
    "Sometimes LLMs generate redundant puzzle so we need to filter out redundant puzzles. Here we can use two different approaches.\n",
    "1. We can use a LLM as classifier to assess based on the semantics if there are duplicates\n",
    "2. We can use a syntactic assessment via a the levenstein distance"
   ],
   "id": "3ed222dcc6056fc4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Levenstein Distance",
   "id": "ad2a2ca050ab63eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T19:39:11.118908Z",
     "start_time": "2025-06-02T19:39:11.103651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.save_and_load_json import load_all_json_files\n",
    "\n",
    "data = load_all_json_files(folder_path='./data/synthetic/gpt_two_calls')"
   ],
   "id": "e0f5f86d4af2e6a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 JSON files from ./data/synthetic/gpt_two_calls\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T19:36:33.188864Z",
     "start_time": "2025-06-02T19:33:24.742271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Levenshtein distance\n",
    "from utils.duplicate_management import find_similar_items\n",
    "\n",
    "keys = ['question', 'question_parsing', 'answer', 'cot', 'cot_parsing']\n",
    "dup = find_similar_items(data, keys_to_compare=keys, threshold=.5)\n",
    "\n",
    "print(dup)"
   ],
   "id": "2b468f878115489c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T15:10:22.035499Z",
     "start_time": "2025-06-02T15:10:22.030594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find a specific item by ID\n",
    "item_1 = next((item for item in data if item.get('id') == 669342), None)\n",
    "item_2 = next((item for item in data if item.get('id') == 129199), None)\n",
    "\n",
    "print(item_1)\n",
    "print(item_2)"
   ],
   "id": "5077f869b0ec15ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'There are five students: A, B, C, D, and E who must be assigned to one of two study groups, X or Y. The following conditions apply: 1) If A is in group X, then B must be in group Y. 2) C and D must be in different groups. 3) If E is in group Y, then C must also be in group Y. 4) A and D cannot be in the same group. Question: If C is in group X, which of the following must be true? a) A is in group X. b) B is in group Y. c) E is in group Y. d) D is in group Y.', 'question_parsing': ['Entities: Students A, B, C, D, E.', 'Initial setup: Assign each to group X or Y.', 'Rule 1: If A is in X, then B is in Y.', 'Rule 2: C and D must be in different groups.', 'Rule 3: If E is in Y, then C is in Y.', 'Rule 4: A and D cannot be in the same group.', 'Specific scenario: C is in group X.'], 'answer': 'd', 'cot': \"Given C is in group X, D must be in group Y (Rule 2). Since A and D cannot be in the same group (Rule 4), A must be in group X. Rule 1 does not force a contradiction here since it would need A to be in group X and B in group Y, which does not conflict with the given scenario. Rule 3 does not apply since E's position is not constrained directly. Therefore, D in group Y is what must be true.\", 'cot_parsing': [{'statement': 'C is in group X, so D must be in group Y.', 'evidence': 'Rule 2: C and D must be in different groups.', 'Verification': 'true'}, {'statement': 'Since D is in Y, A must be in X.', 'evidence': 'Rule 4: A and D cannot be in the same group.', 'Verification': 'true'}], 'id': 669342, 'sel_idx': 669342}\n",
      "{'question': 'Five objects: L, M, N, O, and P must be placed in rooms 1 and 2. The conditions are: 1) If L is in room 1, then M must be in room 2. 2) N and O must be in different rooms. 3) If P is in room 2, then N must also be in room 2. 4) O and P cannot be in room 1 together. Question: If N is in room 1, which of the following must be true? a) L is in room 1. b) M is in room 2. c) P is in room 1. d) O is in room 2.', 'question_parsing': ['Entities: Objects L, M, N, O, P.', 'Initial setup: Assign each to room 1 or room 2.', 'Rule 1: If L is in 1, then M is in 2.', 'Rule 2: N and O must be in different rooms.', 'Rule 3: If P is in 2, then N is in 2.', 'Rule 4: O and P cannot both be in room 1.', 'Specific scenario: N is in room 1.'], 'answer': 'd', 'cot': \"Given N is in room 1, O must be in room 2 (Rule 2). Rule 4 does not apply since it requires both O and P to be in the same room. If P were in room 2, Rule 3 would be violated as N is confirmed in room 1. So, P must be in room 1. None of the constraints force L or M's placement based on the given scenario. Thus, O being in room 2 is the valid deduction.\", 'cot_parsing': [{'statement': 'N in room 1 requires O to be in room 2.', 'evidence': 'Rule 2: N and O in different rooms.', 'Verification': 'true'}, {'statement': 'P cannot be in room 2.', 'evidence': 'To avoid violation of Rule 3 with N in room 1.', 'Verification': 'true'}], 'id': 129199, 'sel_idx': 129199}\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Language Model Classifier\n",
    "\n",
    "Since the syntactic filter indicates that there are no redundancies we will not implement a semantic duplicate finder via a language model."
   ],
   "id": "d9e08b7b6b9e13cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f4ec1f76a20b83a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-nlp-project",
   "language": "python",
   "name": ".venv-nlp-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
