{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["rHND8ErQ_vvm","hJWSRAW9_2Gn"],"authorship_tag":"ABX9TyPpPBz05oe1CPs5sY1xfi85"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 9. Training Two Separate DeBERTa Verifiers\n","\n","In this notebook we train two specialized verifiers for our structured reasoning pipeline:\n","\n","1. **Question Parsing (QP) Verifier**  \n","   - Input: raw question → serialized `question_parsing`  \n","   - Negatives: drop or shuffle constraints  \n","   - Model: `microsoft/deberta-v3-base`, 5 epochs, class-balanced  \n","\n","2. **Chain-of-Thought (CoT) Verifier**  \n","   - Input: question + conditions + CoT → serialized `cot_parsing`  \n","   - Negatives: flip verification, swap/drop evidence  \n","   - Model: `microsoft/deberta-v3-base`, 5 epochs, class-balanced"],"metadata":{"id":"jJzLLhGI_X5p"}},{"cell_type":"markdown","source":["## Imports and Configuration"],"metadata":{"id":"rHND8ErQ_vvm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hqMWLXHB-qAA"},"outputs":[],"source":["import json, random, copy\n","from sklearn.model_selection import train_test_split\n","import torch\n","from collections import Counter\n","from datasets import load_dataset\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    Trainer,\n","    TrainingArguments,\n","    DataCollatorWithPadding\n",")\n","from sklearn.metrics import accuracy_score, f1_score"]},{"cell_type":"markdown","source":["## Data Preparation"],"metadata":{"id":"hJWSRAW9_2Gn"}},{"cell_type":"markdown","source":["### Generate QP Verifier Dataset"],"metadata":{"id":"VedSkHmW_8ym"}},{"cell_type":"code","source":["import json\n","import random\n","from sklearn.model_selection import train_test_split\n","\n","# CONFIGURATION\n","INPUT = \"/content/drive/MyDrive/llm-sr-project/700dataset.json\"\n","OUT_TRAIN = \"/content/drive/MyDrive/llm-sr-project/verifier_qp_train.jsonl\"\n","OUT_DEV = \"/content/drive/MyDrive/llm-sr-project/verifier_qp_dev.jsonl\"\n","NEG_PER_POS = 1  # Number of negative samples to generate per positive\n","DEV_SIZE = 0.1   # Fraction of total data to allocate to dev set\n","\n","\n","def corrupt_question_parsing(qp):\n","    \"\"\"\n","    Corrupts a valid question_parsing (QP) list by:\n","    - Randomly dropping one constraint (if list length > 1), or\n","    - Shuffling the order of constraints\n","    \"\"\"\n","    qp2 = qp.copy()\n","    if random.random() < 0.5 and len(qp2) > 1:\n","        # drop one random item\n","        qp2.pop(random.randrange(len(qp2)))\n","    else:\n","        # shuffle the parsing\n","        random.shuffle(qp2)\n","    return qp2\n","\n","def make_record(question, qp, label):\n","    \"\"\"\n","    Formats a (question, question_parsing) pair into a binary classification example:\n","    - Premise: the raw question text\n","    - Hypothesis: serialized JSON version of QP\n","    - Label: 1 for valid, 0 for corrupted\n","    \"\"\"\n","    premise = question\n","    hyp_qp = json.dumps(qp, ensure_ascii=False)\n","    hypothesis = f\"QuestionParsing: {hyp_qp}\"\n","    return {\"premise\": premise, \"hypothesis\": hypothesis, \"label\": label}\n","\n","def main():\n","    # 1) Load positive (gold) examples from dataset\n","    with open(INPUT, \"r\", encoding=\"utf-8\") as f:\n","        positives = json.load(f)\n","\n","    # 2) For each gold example, generate one valid and several corrupted versions\n","    all_records = []\n","    for ex in positives:\n","        q = ex[\"question\"]\n","        qp = ex[\"question_parsing\"]\n","\n","        # Add the original, valid (label=1)\n","        all_records.append(make_record(q, qp, 1))\n","\n","        # Add corrupted examples (label=0)\n","        for _ in range(NEG_PER_POS):\n","            qp_bad = corrupt_question_parsing(qp)\n","\n","            # Ensure the negative is actually different\n","            if qp_bad != qp:\n","                all_records.append(make_record(q, qp_bad, 0))\n","\n","    # 3) Stratified train/dev split (preserve label ratio)\n","    train, dev = train_test_split(\n","        all_records,\n","        test_size=DEV_SIZE,\n","        random_state=42,\n","        stratify=[r[\"label\"] for r in all_records]\n","    )\n","\n","    # 4) Write train and dev splits as JSONL\n","    for path, split in [(OUT_TRAIN, train), (OUT_DEV, dev)]:\n","        with open(path, \"w\", encoding=\"utf-8\") as f:\n","            for rec in split:\n","                f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n","\n","    print(f\"✔︎ wrote {len(train)} train + {len(dev)} dev QP examples\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"JMKKoJTh_0uS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Define CoT Verifier Dataset"],"metadata":{"id":"sEsKJR5nAFrj"}},{"cell_type":"code","source":["import json\n","import random\n","import copy\n","from sklearn.model_selection import train_test_split\n","\n","# CONFIGURATION\n","INPUT        = \"/content/drive/MyDrive/llm-sr-project/700dataset.json\"\n","OUT_TRAIN    = \"/content/drive/MyDrive/llm-sr-project/verifier_cp_train.jsonl\"\n","OUT_DEV      = \"/content/drive/MyDrive/llm-sr-project/verifier_cp_dev.jsonl\"\n","NEG_PER_POS  = 1    # Number of negative samples to generate per positive\n","DEV_SIZE     = 0.1  # Number of negative samples to generate per positive\n","\n","\n","def corrupt_cot_parsing(cp):\n","    \"\"\"\n","    Corrupts a valid CoT parsing (list of statements with evidence and verification)\n","    by one of the following:\n","    - Flipping the verification field (\"true\" ↔ \"false\")\n","    - Swapping evidence between two statements\n","    - Dropping the evidence field from one step\n","    \"\"\"\n","    cp2 = copy.deepcopy(cp)\n","    if not cp2:\n","        return cp2\n","    choice = random.choice([\"flip\", \"swap\", \"drop_field\"])\n","    if choice == \"flip\":\n","        idx = random.randrange(len(cp2))\n","        cur = cp2[idx].get(\"Verification\", \"false\")\n","        cp2[idx][\"Verification\"] = \"true\" if cur==\"false\" else \"false\"\n","    elif choice == \"swap\" and len(cp2) >= 2:\n","        i, j = random.sample(range(len(cp2)), 2)\n","        cp2[i][\"evidence\"], cp2[j][\"evidence\"] = cp2[j].get(\"evidence\"), cp2[i].get(\"evidence\")\n","    else:\n","        idx = random.randrange(len(cp2))\n","        cp2[idx].pop(\"evidence\", None)\n","    return cp2\n","\n","def make_record(question, cot, conditions, cp, label):\n","    \"\"\"\n","    Formats a (question, CoT, conditions, CoT parsing) pair into a binary classification example:\n","    - Premise: question + conditions + CoT text\n","    - Hypothesis: serialized JSON version of the CoT parsing\n","    - Label: 1 for valid, 0 for corrupted\n","    \"\"\"\n","    cond_block = \"\\n\".join(conditions)\n","    premise    = (\n","        f\"Question:\\n{question}\\n\\n\"\n","        f\"Conditions:\\n{cond_block}\\n\\n\"\n","        f\"CoT:\\n{cot}\"\n","    )\n","    hyp_cp     = json.dumps(cp, ensure_ascii=False)\n","    hypothesis = f\"CoTParsing: {hyp_cp}\"\n","    return {\"premise\": premise, \"hypothesis\": hypothesis, \"label\": label}\n","\n","def main():\n","    # 1) Load gold-labeled examples from dataset\n","    with open(INPUT, \"r\", encoding=\"utf-8\") as f:\n","        positives = json.load(f)\n","\n","    # 2) For each gold example, generate one valid and several corrupted versions\n","    all_records = []\n","    for ex in positives:\n","        q          = ex[\"question\"]\n","        cot        = ex[\"cot\"]\n","        qp         = ex[\"question_parsing\"]\n","        conditions = qp[:-1] if len(qp) > 1 else qp\n","        cp         = ex[\"cot_parsing\"]\n","\n","        # Add the original, valid (label=1)\n","        all_records.append(make_record(q, cot, conditions, cp, 1))\n","\n","        # Add corrupted examples (label=0)\n","        for _ in range(NEG_PER_POS):\n","            cp_bad = corrupt_cot_parsing(cp)\n","            if cp_bad != cp:\n","                all_records.append(make_record(q, cot, conditions, cp_bad, 0))\n","\n","    # 3) Stratified train/dev split (preserve label ratio)\n","    train, dev = train_test_split(\n","        all_records,\n","        test_size=DEV_SIZE,\n","        random_state=42,\n","        stratify=[r[\"label\"] for r in all_records]\n","    )\n","\n","    # 4) Write train and dev splits as JSONL\n","    for path, split in [(OUT_TRAIN, train), (OUT_DEV, dev)]:\n","        with open(path, \"w\", encoding=\"utf-8\") as f:\n","            for rec in split:\n","                f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n","\n","    print(f\"✔︎ wrote {len(train)} train + {len(dev)} dev CP examples\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"DDZ7gdcWAJRE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train QP Verifier"],"metadata":{"id":"XYjvOKTUAXU-"}},{"cell_type":"code","source":["import torch\n","import random\n","from collections import Counter\n","from datasets import load_dataset\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    Trainer,\n","    TrainingArguments,\n","    DataCollatorWithPadding\n",")\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","# CONFIGURATION\n","MODEL_NAME       = \"microsoft/deberta-v3-base\"\n","TRAIN_FILE_QP    = \"/content/drive/MyDrive/llm-sr-project/verifier_qp_train.jsonl\"\n","DEV_FILE_QP      = \"/content/drive/MyDrive/llm-sr-project/verifier_qp_dev.jsonl\"\n","OUTPUT_DIR       = \"/content/drive/MyDrive/deberta-qparse-verifier\"\n","BATCH_SIZE       = 4\n","NUM_EPOCHS       = 5\n","LEARNING_RATE    = 1e-5\n","DEVICE           = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","# 1) Load Dataset\n","ds = load_dataset(\"json\",\n","                  data_files={\"train\": TRAIN_FILE_QP, \"validation\": DEV_FILE_QP})\n","\n","# 2) Balance a split function\n","def balance_split(split_ds):\n","    labels   = split_ds[\"label\"]\n","    idxs_neg = [i for i,l in enumerate(labels) if l == 0]\n","    idxs_pos = [i for i,l in enumerate(labels) if l == 1]\n","\n","    random.seed(42)\n","    # down-sample the larger class\n","    if len(idxs_neg) > len(idxs_pos):\n","        idxs_neg = random.sample(idxs_neg, len(idxs_pos))\n","    else:\n","        idxs_pos = random.sample(idxs_pos, len(idxs_neg))\n","\n","    # combine & shuffle\n","    balanced_idxs = idxs_neg + idxs_pos\n","    random.shuffle(balanced_idxs)\n","    return split_ds.select(balanced_idxs)\n","\n","# 3) Apply to both splits\n","ds[\"train\"]      = balance_split(ds[\"train\"])\n","ds[\"validation\"] = balance_split(ds[\"validation\"])\n","\n","print(\"Balanced train counts:     \", Counter(ds[\"train\"][\"label\"]))\n","print(\"Balanced validation counts:\", Counter(ds[\"validation\"][\"label\"]))\n","\n","\n","# 2) Tokenizer & Model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model     = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n","model.to(DEVICE)\n","\n","data_collator = DataCollatorWithPadding(tokenizer)\n","\n","def preprocess(examples):\n","    enc = tokenizer(\n","        examples[\"premise\"],\n","        examples[\"hypothesis\"],\n","        truncation=True\n","    )\n","    enc[\"labels\"] = examples[\"label\"]\n","    return enc\n","\n","tok_ds = ds.map(preprocess, batched=True, remove_columns=ds[\"train\"].column_names)\n","\n","# 3) Metrics\n","def compute_metrics(p):\n","    preds = p.predictions.argmax(-1)\n","    labels = p.label_ids\n","    return {\n","        \"accuracy\": accuracy_score(labels, preds),\n","        \"f1\":       f1_score(labels, preds),\n","    }\n","\n","# 4) TrainingArguments & Trainer\n","training_args = TrainingArguments(\n","    output_dir=OUTPUT_DIR,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE * 2,\n","    learning_rate=LEARNING_RATE,\n","    num_train_epochs=NUM_EPOCHS,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1\",\n","    logging_steps=50,\n","    fp16=True,\n","    report_to=\"none\"\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tok_ds[\"train\"],\n","    eval_dataset=tok_ds[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# 5) Train & Save\n","trainer.train()\n","trainer.save_model(OUTPUT_DIR)\n","tokenizer.save_pretrained(OUTPUT_DIR)\n","print(\"✅ QP verifier trained and saved to\", OUTPUT_DIR)"],"metadata":{"id":"h3tkwr2zAaXQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train CoT Verifier"],"metadata":{"id":"3MDc2E_nAdSA"}},{"cell_type":"code","source":["import torch\n","import random\n","from collections import Counter\n","from datasets import load_dataset\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    Trainer,\n","    TrainingArguments,\n","    DataCollatorWithPadding\n",")\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","# CONFIGURATION\n","MODEL_NAME       = \"microsoft/deberta-v3-base\"\n","TRAIN_FILE_CP    = \"/content/drive/MyDrive/llm-sr-project/verifier_cp_train.jsonl\"\n","DEV_FILE_CP      = \"/content/drive/MyDrive/llm-sr-project/verifier_cp_dev.jsonl\"\n","OUTPUT_DIR       = \"/content/drive/MyDrive/deberta-cotparse-verifier\"\n","BATCH_SIZE       = 4\n","NUM_EPOCHS       = 5\n","LEARNING_RATE    = 1e-5\n","DEVICE           = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 1) Load Dataset\n","ds = load_dataset(\"json\",\n","                  data_files={\"train\": TRAIN_FILE_CP, \"validation\": DEV_FILE_CP})\n","\n","# 2) Balance a split function\n","def balance_split(split_ds):\n","    labels   = split_ds[\"label\"]\n","    idxs_neg = [i for i,l in enumerate(labels) if l == 0]\n","\n","\n","    idxs_pos = [i for i,l in enumerate(labels) if l == 1]\n","\n","    random.seed(42)\n","    # down-sample the larger class\n","    if len(idxs_neg) > len(idxs_pos):\n","        idxs_neg = random.sample(idxs_neg, len(idxs_pos))\n","    else:\n","        idxs_pos = random.sample(idxs_pos, len(idxs_neg))\n","\n","    # combine & shuffle\n","    balanced_idxs = idxs_neg + idxs_pos\n","    random.shuffle(balanced_idxs)\n","    return split_ds.select(balanced_idxs)\n","\n","# 3) Apply to both splits\n","ds[\"train\"]      = balance_split(ds[\"train\"])\n","ds[\"validation\"] = balance_split(ds[\"validation\"])\n","\n","print(\"Balanced train counts:     \", Counter(ds[\"train\"][\"label\"]))\n","print(\"Balanced validation counts:\", Counter(ds[\"validation\"][\"label\"]))\n","\n","# 4) Tokenizer & Model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model     = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n","model.to(DEVICE)\n","\n","data_collator = DataCollatorWithPadding(tokenizer)\n","\n","def preprocess(examples):\n","    enc = tokenizer(\n","        examples[\"premise\"],\n","        examples[\"hypothesis\"],\n","        truncation=True\n","    )\n","    enc[\"labels\"] = examples[\"label\"]\n","    return enc\n","\n","tok_ds = ds.map(preprocess, batched=True, remove_columns=ds[\"train\"].column_names)\n","\n","# 5) Metrics\n","def compute_metrics(p):\n","    preds  = p.predictions.argmax(-1)\n","    labels = p.label_ids\n","    return {\n","        \"accuracy\": accuracy_score(labels, preds),\n","        \"f1\":       f1_score(labels, preds),\n","    }\n","\n","# 6) TrainingArguments & Trainer\n","training_args = TrainingArguments(\n","    output_dir=OUTPUT_DIR,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE * 2,\n","    learning_rate=LEARNING_RATE,\n","    num_train_epochs=NUM_EPOCHS,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1\",\n","    logging_steps=50,\n","    fp16=True,\n","    report_to=\"none\"\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tok_ds[\"train\"],\n","    eval_dataset=tok_ds[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# 7) Train & Save\n","trainer.train()\n","trainer.save_model(OUTPUT_DIR)\n","tokenizer.save_pretrained(OUTPUT_DIR)\n","print(\"✅ CP verifier trained and saved to\", OUTPUT_DIR)"],"metadata":{"id":"3oJgSM2qAc03"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Next Steps\n","\n","- Both verifiers have been saved to:\n","  - `deberta-qparse-verifier/`\n","  - `deberta-cotparse-verifier/`\n","\n","- In the next notebook, we will integrate these two models into our hybrid inference pipeline to rerank and validate Chain-of-Thought parses.\n"],"metadata":{"id":"94ax9eQ5AqQb"}}]}