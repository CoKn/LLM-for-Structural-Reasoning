{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJzLLhGI_X5p"
   },
   "source": [
    "# 9. Training Two Separate DeBERTa Verifiers\n",
    "\n",
    "In this notebook we train two specialized verifiers for our structured reasoning pipeline:\n",
    "\n",
    "1. **Question Parsing (QP) Verifier**  \n",
    "   - Input: raw question → serialized `question_parsing`  \n",
    "   - Negatives: drop or shuffle constraints  \n",
    "   - Model: `microsoft/deberta-v3-base`, 5 epochs, class-balanced  \n",
    "\n",
    "2. **Chain-of-Thought (CoT) Verifier**  \n",
    "   - Input: question + conditions + CoT → serialized `cot_parsing`  \n",
    "   - Negatives: flip verification, swap/drop evidence  \n",
    "   - Model: `microsoft/deberta-v3-base`, 5 epochs, class-balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHND8ErQ_vvm"
   },
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqMWLXHB-qAA"
   },
   "outputs": [],
   "source": [
    "import json, random, copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJWSRAW9_2Gn"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VedSkHmW_8ym"
   },
   "source": [
    "### Generate QP Verifier Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JMKKoJTh_0uS",
    "outputId": "34c93cc6-4316-4b09-8f45-5c29a13c33c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔︎ wrote 694 train + 78 dev QP examples\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CONFIGURATION\n",
    "INPUT = \"/content/drive/MyDrive/llm-sr-project/700dataset.json\"\n",
    "OUT_TRAIN = \"/content/drive/MyDrive/llm-sr-project/verifier_qp_train.jsonl\"\n",
    "OUT_DEV = \"/content/drive/MyDrive/llm-sr-project/verifier_qp_dev.jsonl\"\n",
    "NEG_PER_POS = 1  # Number of negative samples to generate per positive\n",
    "DEV_SIZE = 0.1   # Fraction of total data to allocate to dev set\n",
    "\n",
    "\n",
    "def corrupt_question_parsing(qp):\n",
    "    \"\"\"\n",
    "    Corrupts a valid question_parsing (QP) list by:\n",
    "    - Randomly dropping one constraint (if list length > 1), or\n",
    "    - Shuffling the order of constraints\n",
    "    \"\"\"\n",
    "    qp2 = qp.copy()\n",
    "    if random.random() < 0.5 and len(qp2) > 1:\n",
    "        # drop one random item\n",
    "        qp2.pop(random.randrange(len(qp2)))\n",
    "    else:\n",
    "        # shuffle the parsing\n",
    "        random.shuffle(qp2)\n",
    "    return qp2\n",
    "\n",
    "def make_record(question, qp, label):\n",
    "    \"\"\"\n",
    "    Formats a (question, question_parsing) pair into a binary classification example:\n",
    "    - Premise: the raw question text\n",
    "    - Hypothesis: serialized JSON version of QP\n",
    "    - Label: 1 for valid, 0 for corrupted\n",
    "    \"\"\"\n",
    "    premise = question\n",
    "    hyp_qp = json.dumps(qp, ensure_ascii=False)\n",
    "    hypothesis = f\"QuestionParsing: {hyp_qp}\"\n",
    "    return {\"premise\": premise, \"hypothesis\": hypothesis, \"label\": label}\n",
    "\n",
    "def main():\n",
    "    # 1) Load positive (gold) examples from dataset\n",
    "    with open(INPUT, \"r\", encoding=\"utf-8\") as f:\n",
    "        positives = json.load(f)\n",
    "\n",
    "    # 2) For each gold example, generate one valid and several corrupted versions\n",
    "    all_records = []\n",
    "    for ex in positives:\n",
    "        q = ex[\"question\"]\n",
    "        qp = ex[\"question_parsing\"]\n",
    "\n",
    "        # Add the original, valid (label=1)\n",
    "        all_records.append(make_record(q, qp, 1))\n",
    "\n",
    "        # Add corrupted examples (label=0)\n",
    "        for _ in range(NEG_PER_POS):\n",
    "            qp_bad = corrupt_question_parsing(qp)\n",
    "\n",
    "            # Ensure the negative is actually different\n",
    "            if qp_bad != qp:\n",
    "                all_records.append(make_record(q, qp_bad, 0))\n",
    "\n",
    "    # 3) Stratified train/dev split (preserve label ratio)\n",
    "    train, dev = train_test_split(\n",
    "        all_records,\n",
    "        test_size=DEV_SIZE,\n",
    "        random_state=42,\n",
    "        stratify=[r[\"label\"] for r in all_records]\n",
    "    )\n",
    "\n",
    "    # 4) Write train and dev splits as JSONL\n",
    "    for path, split in [(OUT_TRAIN, train), (OUT_DEV, dev)]:\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for rec in split:\n",
    "                f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"✔︎ wrote {len(train)} train + {len(dev)} dev QP examples\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEsKJR5nAFrj"
   },
   "source": [
    "### Define CoT Verifier Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DDZ7gdcWAJRE",
    "outputId": "ef5c8176-9631-46ea-ae6e-1115d440da63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔︎ wrote 703 train + 79 dev CP examples\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CONFIGURATION\n",
    "INPUT        = \"/content/drive/MyDrive/llm-sr-project/700dataset.json\"\n",
    "OUT_TRAIN    = \"/content/drive/MyDrive/llm-sr-project/verifier_cp_train.jsonl\"\n",
    "OUT_DEV      = \"/content/drive/MyDrive/llm-sr-project/verifier_cp_dev.jsonl\"\n",
    "NEG_PER_POS  = 1    # Number of negative samples to generate per positive\n",
    "DEV_SIZE     = 0.1  # Number of negative samples to generate per positive\n",
    "\n",
    "\n",
    "def corrupt_cot_parsing(cp):\n",
    "    \"\"\"\n",
    "    Corrupts a valid CoT parsing (list of statements with evidence and verification)\n",
    "    by one of the following:\n",
    "    - Flipping the verification field (\"true\" ↔ \"false\")\n",
    "    - Swapping evidence between two statements\n",
    "    - Dropping the evidence field from one step\n",
    "    \"\"\"\n",
    "    cp2 = copy.deepcopy(cp)\n",
    "    if not cp2:\n",
    "        return cp2\n",
    "    choice = random.choice([\"flip\", \"swap\", \"drop_field\"])\n",
    "    if choice == \"flip\":\n",
    "        idx = random.randrange(len(cp2))\n",
    "        cur = cp2[idx].get(\"Verification\", \"false\")\n",
    "        cp2[idx][\"Verification\"] = \"true\" if cur==\"false\" else \"false\"\n",
    "    elif choice == \"swap\" and len(cp2) >= 2:\n",
    "        i, j = random.sample(range(len(cp2)), 2)\n",
    "        cp2[i][\"evidence\"], cp2[j][\"evidence\"] = cp2[j].get(\"evidence\"), cp2[i].get(\"evidence\")\n",
    "    else:\n",
    "        idx = random.randrange(len(cp2))\n",
    "        cp2[idx].pop(\"evidence\", None)\n",
    "    return cp2\n",
    "\n",
    "def make_record(question, cot, conditions, cp, label):\n",
    "    \"\"\"\n",
    "    Formats a (question, CoT, conditions, CoT parsing) pair into a binary classification example:\n",
    "    - Premise: question + conditions + CoT text\n",
    "    - Hypothesis: serialized JSON version of the CoT parsing\n",
    "    - Label: 1 for valid, 0 for corrupted\n",
    "    \"\"\"\n",
    "    cond_block = \"\\n\".join(conditions)\n",
    "    premise    = (\n",
    "        f\"Question:\\n{question}\\n\\n\"\n",
    "        f\"Conditions:\\n{cond_block}\\n\\n\"\n",
    "        f\"CoT:\\n{cot}\"\n",
    "    )\n",
    "    hyp_cp     = json.dumps(cp, ensure_ascii=False)\n",
    "    hypothesis = f\"CoTParsing: {hyp_cp}\"\n",
    "    return {\"premise\": premise, \"hypothesis\": hypothesis, \"label\": label}\n",
    "\n",
    "def main():\n",
    "    # 1) Load gold-labeled examples from dataset\n",
    "    with open(INPUT, \"r\", encoding=\"utf-8\") as f:\n",
    "        positives = json.load(f)\n",
    "\n",
    "    # 2) For each gold example, generate one valid and several corrupted versions\n",
    "    all_records = []\n",
    "    for ex in positives:\n",
    "        q          = ex[\"question\"]\n",
    "        cot        = ex[\"cot\"]\n",
    "        qp         = ex[\"question_parsing\"]\n",
    "        conditions = qp[:-1] if len(qp) > 1 else qp\n",
    "        cp         = ex[\"cot_parsing\"]\n",
    "\n",
    "        # Add the original, valid (label=1)\n",
    "        all_records.append(make_record(q, cot, conditions, cp, 1))\n",
    "\n",
    "        # Add corrupted examples (label=0)\n",
    "        for _ in range(NEG_PER_POS):\n",
    "            cp_bad = corrupt_cot_parsing(cp)\n",
    "            if cp_bad != cp:\n",
    "                all_records.append(make_record(q, cot, conditions, cp_bad, 0))\n",
    "\n",
    "    # 3) Stratified train/dev split (preserve label ratio)\n",
    "    train, dev = train_test_split(\n",
    "        all_records,\n",
    "        test_size=DEV_SIZE,\n",
    "        random_state=42,\n",
    "        stratify=[r[\"label\"] for r in all_records]\n",
    "    )\n",
    "\n",
    "    # 4) Write train and dev splits as JSONL\n",
    "    for path, split in [(OUT_TRAIN, train), (OUT_DEV, dev)]:\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for rec in split:\n",
    "                f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"✔︎ wrote {len(train)} train + {len(dev)} dev CP examples\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYjvOKTUAXU-"
   },
   "source": [
    "## Train QP Verifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734,
     "referenced_widgets": [
      "29ca1b1fc61e4cbc9ed254a684b4f387",
      "0ca5ad9bdd9742328d557309667bc008",
      "e4f8b3137e9c4d8282a2729365410480",
      "1bc5b8b151ad426d81e5414cc5282e35",
      "adaf6694fea34fe0bb14781d51df36af",
      "d8e204207f844fd1b8948d5b5efc9865",
      "abfd5659195b4c00ad3d78758d5d64ed",
      "92b59ffc0e034e36af4dd77d42128239",
      "483561a7f27d4dd982f0ff0306aa1f4b",
      "df1bf73b29024c10b13e6ef26b63df5e",
      "8777ea591a42400baa39c7ffef6c8207",
      "842399e40cb844449a2ade8f82f75587",
      "fa0c152061404722a644450c8bbb87f9",
      "a25a4ee97aa1492c8f5010147c94773f",
      "60344c00c7a94098a97a43f8e37c0d1e",
      "9d919bff0907439ba98c15d696ae1ea0",
      "980e545e3f1c414db36ea3c10e3c5cfb",
      "d0d322cb81a5490b8820c83ffbc16358",
      "f4b2c900850b415b9e0ef7351415cf29",
      "a0911c0298a04715b2c114ac307acaf2",
      "1be545d240084d579cca867de37211cf",
      "deeff24c51dd40ba9bcb9d3921cf1222",
      "6f330636b9c94e09aca002a2d9d64218",
      "607030d157a74a1ca9aaf06d359fcb67",
      "bb1ca604cf2543beac179d351ded8ec5",
      "80a6a2eeb4d74dbf9bc81db8712c25d2",
      "1089bb645a7f435f8d8bdb6f347f0bf1",
      "f6be7d7709934af98b7115eaecbcbeea",
      "f73225df250c4fc09989ce6a82f43740",
      "b5d434bdf22643dfb93d14e4680bdb53",
      "4bebf0caed714784bef7ce0cd28a0856",
      "3a4b2b1d6cb840feaf2fcc91f1511af2",
      "6635f259da5c4782806ec37d955d51c2",
      "355881392b7845ac837ca34488163344",
      "d5699a2e9f44425d87daa60e608b6826",
      "a3478640c79c4eaeaa3460c23aa28f67",
      "bc7c09906a274b0480bffcdceedb9a1c",
      "eb6b28cbc3034e53b0cf7898600562d4",
      "7767f3796f634ca3863af149a6cacc78",
      "50475cd26d1a494baca8ccd5374b8fec",
      "cee7384941224365b3cc49c0dc248c25",
      "d4fa5eec0ab644c9867af029dd6505e0",
      "30040e36cc6a4bf48205f8a2fb3ecb38",
      "4f600d2244f54c4bb0a1d6b995d9c8eb",
      "da845641b90b45fbb6a442360bcf67bb",
      "fedcfcc13f20450a9556e54928228a77",
      "d80abe40d10d46e6a06ebd37b5293fc3",
      "5614d6c840da45e8ad747ba0f3a9b775",
      "04821febc9eb4d8c9f0db9da59177a29",
      "9ef7d9b4cc19471583514a0aa6b1617f",
      "9cc95dc0921042aca60e61dd20f21b12",
      "8fbb2efe8fc1465581c5defdf1155200",
      "0d99d9cfb5f74dc284f9b08307d32681",
      "1bdf29ba5ffa4890a122ae9dd52069cf",
      "8869496a5ada4e4abda8a662cc3574be",
      "12b5540714374930b69a104d73d4ce2c",
      "baff3e59ebe7489db653f248a02dcea1",
      "216d8a3383c94c4f97ecae88d9d6ac59",
      "275f8ef68fb34fa893743d36e984ddcc",
      "e908f5dcb73947819bda2a5edba4cdc0",
      "7eb7386371ff40c180a40cb769f2eec3",
      "7ef20eadf46f4e9bb43fb4daec12c399",
      "4a23ed8c188741cdbf3145819acec0b4",
      "e16ec17dc8fd4337a147f07f51fcf179",
      "84e2747d4b054834b0e5fb9e45e542f3",
      "f3ba79d1e9964366b305cdd37c199cce",
      "864de7290a3742be8ec44596443402d2",
      "6bb1ec0b5e8f4c06ab3582ecb569b683",
      "cd6012dc063e49f785e00e7b4fdc251d",
      "3ce185683e38489897ce0cd9cf2b0314",
      "b7fedad1c6ab4661bbebc0600e86bac7",
      "a21d71c730254b65b90c3643aa93de56",
      "acc5768e82ac47c2b3efe5f419421a19",
      "d1355b178bb7445984c80044edc077e2",
      "4b71ac5c835840a1b91a05ee39fa96dc",
      "962e0cd5dbc947f599f7d32ca6ea718f",
      "0b110358d2e140b19c30631dc94fb637"
     ]
    },
    "id": "h3tkwr2zAaXQ",
    "outputId": "55ae03e1-537e-4968-b8b2-361e068fe28d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced train counts:      Counter({0: 343, 1: 343})\n",
      "Balanced validation counts: Counter({0: 38, 1: 38})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ca1b1fc61e4cbc9ed254a684b4f387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842399e40cb844449a2ade8f82f75587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f330636b9c94e09aca002a2d9d64218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355881392b7845ac837ca34488163344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da845641b90b45fbb6a442360bcf67bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b5540714374930b69a104d73d4ce2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/686 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864de7290a3742be8ec44596443402d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/76 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-87f0c796dbbc>:111: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='860' max='860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [860/860 02:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.683000</td>\n",
       "      <td>0.657719</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.540600</td>\n",
       "      <td>0.563493</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.563400</td>\n",
       "      <td>0.562213</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.781609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.397500</td>\n",
       "      <td>0.794427</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.767442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.379800</td>\n",
       "      <td>0.855469</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.771084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ QP verifier trained and saved to /content/drive/MyDrive/deberta-qparse-verifier\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "import json\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# CONFIGURATION\n",
    "MODEL_NAME       = \"microsoft/deberta-v3-base\"\n",
    "TRAIN_FILE_QP    = \"/content/drive/MyDrive/llm-sr-project/verifier_qp_train.jsonl\"\n",
    "DEV_FILE_QP      = \"/content/drive/MyDrive/llm-sr-project/verifier_qp_dev.jsonl\"\n",
    "OUTPUT_DIR       = \"/content/drive/MyDrive/deberta-qparse-verifier\"\n",
    "BATCH_SIZE       = 4\n",
    "NUM_EPOCHS       = 5\n",
    "LEARNING_RATE    = 1e-5\n",
    "DEVICE           = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# 1) Load Dataset\n",
    "def load_jsonl(path):\n",
    "    with open(path, \"r\") as f:\n",
    "       return [json.loads(line) for line in f]\n",
    "\n",
    "train_data = load_jsonl(TRAIN_FILE_QP)\n",
    "val_data   = load_jsonl(DEV_FILE_QP)\n",
    "\n",
    "ds = DatasetDict({\n",
    "    \"train\": Dataset.from_list(train_data),\n",
    "    \"validation\": Dataset.from_list(val_data)\n",
    "})\n",
    "\n",
    "#ds = load_dataset(\"json\", data_files={\"train\": TRAIN_FILE_QP, \"validation\": DEV_FILE_QP})\n",
    "\n",
    "# 2) Balance a split function\n",
    "def balance_split(split_ds):\n",
    "    labels   = split_ds[\"label\"]\n",
    "    idxs_neg = [i for i,l in enumerate(labels) if l == 0]\n",
    "    idxs_pos = [i for i,l in enumerate(labels) if l == 1]\n",
    "\n",
    "    random.seed(42)\n",
    "    # down-sample the larger class\n",
    "    if len(idxs_neg) > len(idxs_pos):\n",
    "        idxs_neg = random.sample(idxs_neg, len(idxs_pos))\n",
    "    else:\n",
    "        idxs_pos = random.sample(idxs_pos, len(idxs_neg))\n",
    "\n",
    "    # combine & shuffle\n",
    "    balanced_idxs = idxs_neg + idxs_pos\n",
    "    random.shuffle(balanced_idxs)\n",
    "    return split_ds.select(balanced_idxs)\n",
    "\n",
    "# 3) Apply to both splits\n",
    "ds[\"train\"]      = balance_split(ds[\"train\"])\n",
    "ds[\"validation\"] = balance_split(ds[\"validation\"])\n",
    "\n",
    "print(\"Balanced train counts:     \", Counter(ds[\"train\"][\"label\"]))\n",
    "print(\"Balanced validation counts:\", Counter(ds[\"validation\"][\"label\"]))\n",
    "\n",
    "\n",
    "# 2) Tokenizer & Model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "model.to(DEVICE)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "def preprocess(examples):\n",
    "    enc = tokenizer(\n",
    "        examples[\"premise\"],\n",
    "        examples[\"hypothesis\"],\n",
    "        truncation=True\n",
    "    )\n",
    "    enc[\"labels\"] = examples[\"label\"]\n",
    "    return enc\n",
    "\n",
    "tok_ds = ds.map(preprocess, batched=True, remove_columns=ds[\"train\"].column_names)\n",
    "\n",
    "# 3) Metrics\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\":       f1_score(labels, preds),\n",
    "    }\n",
    "\n",
    "# 4) TrainingArguments & Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=50,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tok_ds[\"train\"],\n",
    "    eval_dataset=tok_ds[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 5) Train & Save\n",
    "trainer.train()\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(\"✅ QP verifier trained and saved to\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "vSs-8MJ0AUmu"
   },
   "outputs": [],
   "source": [
    "!rm -rf \"/content/drive/MyDrive/deberta-qparse-verifier/checkpoint-\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WefCcbvmBu_r",
    "outputId": "788b6c39-8dcf-4efb-8b16-db5259b80098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added_tokens.json  special_tokens_map.json  tokenizer.json\n",
      "config.json\t   spm.model\t\t    training_args.bin\n",
      "model.safetensors  tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls \"/content/drive/MyDrive/deberta-qparse-verifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qG1Ndjv1d1c",
    "outputId": "d7f9d4f5-877e-4429-8b3a-5b8c5e9e5d3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: content/drive/MyDrive/deberta-qparse-verifier/ (stored 0%)\n",
      "updating: content/drive/MyDrive/deberta-qparse-verifier/config.json (deflated 54%)\n",
      "updating: content/drive/MyDrive/deberta-qparse-verifier/model.safetensors (deflated 25%)\n",
      "updating: content/drive/MyDrive/deberta-qparse-verifier/tokenizer_config.json (deflated 73%)\n",
      "updating: content/drive/MyDrive/deberta-qparse-verifier/training_args.bin (deflated 51%)\n",
      "updating: content/drive/MyDrive/deberta-qparse-verifier/added_tokens.json (stored 0%)\n",
      "updating: content/drive/MyDrive/deberta-qparse-verifier/spm.model (deflated 50%)\n",
      "updating: content/drive/MyDrive/deberta-qparse-verifier/special_tokens_map.json (deflated 50%)\n",
      "updating: content/drive/MyDrive/deberta-qparse-verifier/tokenizer.json (deflated 77%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /content/drive/MyDrive/deberta-qparse-verifier.zip \"/content/drive/MyDrive/deberta-qparse-verifier\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MDc2E_nAdSA"
   },
   "source": [
    "## Train CoT Verifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475,
     "referenced_widgets": [
      "40e87f414a1b4d7d9075cebfde0c0ff1",
      "e99d3adb672c4cfeaeec1a1d2b47f7ed",
      "ee1c32f29fa6492db662ff1bca7e6acd",
      "f0d6f21c814248d3a6a35d8ddca0fcae",
      "6f5929ad92c8492d9714b619100aa67d",
      "0f2a998e27634a889f332a8d81b55097",
      "700bb9361fad401ca66dd2756d7d052e",
      "eb86b22a90464ccf8d3a22e68f4bafb5",
      "e2b151c581844cc58f93036f906a6227",
      "20cdacfd28874f94807012523d195b27",
      "d9ef05fe73164d36af40b1693dad1520",
      "2176e8d5bc154fff8f96f721ca5f5c53",
      "54111af1d33d45b5bd93fc64eedd45a2",
      "ca2a4aa4884a416b9a11f66567b04c1d",
      "adc958cc1bb5488db447eed0095f681d",
      "09ad35c805574f19b4b22cd7956a2d89",
      "949bc4cd94f24fb6b63f2a5ad3145f51",
      "801937dc6c744a7982e78e121e80da48",
      "56ad08d78ce4465797e0ec62d3f8b67e",
      "39ea2fac1aef4a1cbb8c4a2b1a36b853",
      "c4a784fad77e497baf8c1fb50604d386",
      "75aa98a4b866438eb2aa61c2c341ea75"
     ]
    },
    "id": "3oJgSM2qAc03",
    "outputId": "f1574973-5145-4407-9e27-636b6e272c8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced train counts:      Counter({0: 343, 1: 343})\n",
      "Balanced validation counts: Counter({0: 38, 1: 38})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e87f414a1b4d7d9075cebfde0c0ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/686 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2176e8d5bc154fff8f96f721ca5f5c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/76 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-cede48a6fa05>:110: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='860' max='860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [860/860 02:02, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693300</td>\n",
       "      <td>0.693211</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.651300</td>\n",
       "      <td>0.576170</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.757895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.552300</td>\n",
       "      <td>0.537043</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.763158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.372300</td>\n",
       "      <td>0.652095</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.399100</td>\n",
       "      <td>0.721006</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.804878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CP verifier trained and saved to /content/drive/MyDrive/deberta-cotparse-verifier\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# CONFIGURATION\n",
    "MODEL_NAME       = \"microsoft/deberta-v3-base\"\n",
    "TRAIN_FILE_CP    = \"/content/drive/MyDrive/llm-sr-project/verifier_cp_train.jsonl\"\n",
    "DEV_FILE_CP      = \"/content/drive/MyDrive/llm-sr-project/verifier_cp_dev.jsonl\"\n",
    "OUTPUT_DIR       = \"/content/drive/MyDrive/deberta-cotparse-verifier\"\n",
    "BATCH_SIZE       = 4\n",
    "NUM_EPOCHS       = 5\n",
    "LEARNING_RATE    = 1e-5\n",
    "DEVICE           = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1) Load Dataset\n",
    "def load_jsonl(path):\n",
    "    with open(path, \"r\") as f:\n",
    "       return [json.loads(line) for line in f]\n",
    "\n",
    "train_data = load_jsonl(TRAIN_FILE_QP)\n",
    "val_data   = load_jsonl(DEV_FILE_QP)\n",
    "\n",
    "ds = DatasetDict({\n",
    "    \"train\": Dataset.from_list(train_data),\n",
    "    \"validation\": Dataset.from_list(val_data)\n",
    "})\n",
    "\n",
    "\n",
    "#ds = load_dataset(\"json\",data_files={\"train\": TRAIN_FILE_CP, \"validation\": DEV_FILE_CP})\n",
    "\n",
    "# 2) Balance a split function\n",
    "def balance_split(split_ds):\n",
    "    labels   = split_ds[\"label\"]\n",
    "    idxs_neg = [i for i,l in enumerate(labels) if l == 0]\n",
    "\n",
    "\n",
    "    idxs_pos = [i for i,l in enumerate(labels) if l == 1]\n",
    "\n",
    "    random.seed(42)\n",
    "    # down-sample the larger class\n",
    "    if len(idxs_neg) > len(idxs_pos):\n",
    "        idxs_neg = random.sample(idxs_neg, len(idxs_pos))\n",
    "    else:\n",
    "        idxs_pos = random.sample(idxs_pos, len(idxs_neg))\n",
    "\n",
    "    # combine & shuffle\n",
    "    balanced_idxs = idxs_neg + idxs_pos\n",
    "    random.shuffle(balanced_idxs)\n",
    "    return split_ds.select(balanced_idxs)\n",
    "\n",
    "# 3) Apply to both splits\n",
    "ds[\"train\"]      = balance_split(ds[\"train\"])\n",
    "ds[\"validation\"] = balance_split(ds[\"validation\"])\n",
    "\n",
    "print(\"Balanced train counts:     \", Counter(ds[\"train\"][\"label\"]))\n",
    "print(\"Balanced validation counts:\", Counter(ds[\"validation\"][\"label\"]))\n",
    "\n",
    "# 4) Tokenizer & Model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "model.to(DEVICE)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "def preprocess(examples):\n",
    "    enc = tokenizer(\n",
    "        examples[\"premise\"],\n",
    "        examples[\"hypothesis\"],\n",
    "        truncation=True\n",
    "    )\n",
    "    enc[\"labels\"] = examples[\"label\"]\n",
    "    return enc\n",
    "\n",
    "tok_ds = ds.map(preprocess, batched=True, remove_columns=ds[\"train\"].column_names)\n",
    "\n",
    "# 5) Metrics\n",
    "def compute_metrics(p):\n",
    "    preds  = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\":       f1_score(labels, preds),\n",
    "    }\n",
    "\n",
    "# 6) TrainingArguments & Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=50,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tok_ds[\"train\"],\n",
    "    eval_dataset=tok_ds[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 7) Train & Save\n",
    "trainer.train()\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(\"✅ CP verifier trained and saved to\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "d0di7_XYEc8y"
   },
   "outputs": [],
   "source": [
    "!rm -rf \"/content/drive/MyDrive/deberta-cotparse-verifier/checkpoint-\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DnaqEUQCEdK0",
    "outputId": "e5ff9864-2691-473e-e88b-29171e805281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added_tokens.json  special_tokens_map.json  tokenizer.json\n",
      "config.json\t   spm.model\t\t    training_args.bin\n",
      "model.safetensors  tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls \"/content/drive/MyDrive/deberta-cotparse-verifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XZVGxxxfEo3i",
    "outputId": "e24bc6f8-dc90-48ed-fe40-9a92be16f2a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: content/drive/MyDrive/deberta-cotparse-verifier/ (stored 0%)\n",
      "updating: content/drive/MyDrive/deberta-cotparse-verifier/config.json (deflated 54%)\n",
      "updating: content/drive/MyDrive/deberta-cotparse-verifier/model.safetensors (deflated 25%)\n",
      "updating: content/drive/MyDrive/deberta-cotparse-verifier/training_args.bin (deflated 52%)\n",
      "updating: content/drive/MyDrive/deberta-cotparse-verifier/special_tokens_map.json (deflated 50%)\n",
      "updating: content/drive/MyDrive/deberta-cotparse-verifier/tokenizer_config.json (deflated 73%)\n",
      "updating: content/drive/MyDrive/deberta-cotparse-verifier/spm.model (deflated 50%)\n",
      "updating: content/drive/MyDrive/deberta-cotparse-verifier/tokenizer.json (deflated 77%)\n",
      "updating: content/drive/MyDrive/deberta-cotparse-verifier/added_tokens.json (stored 0%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /content/drive/MyDrive/deberta-cotparse-verifier.zip \"/content/drive/MyDrive/deberta-cotparse-verifier\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94ax9eQ5AqQb"
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "- Both verifiers have been saved to:\n",
    "  - `deberta-qparse-verifier/`\n",
    "  - `deberta-cotparse-verifier/`\n",
    "\n",
    "- In the next notebook, we will integrate these two models into our hybrid inference pipeline to rerank and validate Chain-of-Thought parses.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
