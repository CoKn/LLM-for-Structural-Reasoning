{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "oCV51kAAqFs4",
        "1OZYB32BsB19",
        "xcJ1WrOmsQQQ",
        "czHV3tuGsVRK",
        "KzmcFxEVsykV"
      ],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 6. DeepSeek Benchmark\n",
        "\n",
        "**Purpose:**  \n",
        "Fine-tune DeepSeek–Coder-6.7B-Instruct with LoRA adapters as a benchmark against our LLaMA-3 pipeline.  \n",
        "We train two adapter-only variants:\n",
        "- **DeepSeek QP**: on `train_question_parsing.jsonl`  \n",
        "- **DeepSeek CoT**: on `train_cot_parsing.jsonl`  \n",
        "\n",
        "Then we run inference+evaluation exactly like before.\n"
      ],
      "metadata": {
        "id": "9fZRKNxhp5lz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "oCV51kAAqFs4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cGaP9jJDo2O0"
      },
      "outputs": [],
      "source": [
        "# Install Unsloth for efficient LLM fine-tuning\n",
        "%%capture\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install core evaluation utilities\n",
        "!pip install -q evaluate\n",
        "!pip install json5\n",
        "\n",
        "!pip uninstall -y nltk\n",
        "!pip install -q --upgrade nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMTA3JdNr7fA",
        "outputId": "fb05ea82-ba0e-49c7-f5bd-65a95d54b008"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting json5\n",
            "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "Downloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: json5\n",
            "Successfully installed json5-0.12.0\n",
            "Found existing installation: nltk 3.9.1\n",
            "Uninstalling nltk-3.9.1:\n",
            "  Successfully uninstalled nltk-3.9.1\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM8igtxyr4pU",
        "outputId": "620e74e3-fb9c-4310-88e5-0a85e79bddd3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unsloth\n",
        "import os\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset\n",
        "import gc\n",
        "from transformers import TrainingArguments, Trainer, AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
        "import json, re, ast, html"
      ],
      "metadata": {
        "id": "VxNp6juAqKKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common Config"
      ],
      "metadata": {
        "id": "1OZYB32BsB19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_DIR = \"/content/drive/MyDrive/llm-sr-project\"\n",
        "os.environ[\"USE_XFORMERS\"] = \"false\"    # for Colab compatibility\n",
        "\n",
        "# paths\n",
        "QP_TRAIN = os.path.join(PROJECT_DIR, \"train_question_parsing.jsonl\")\n",
        "COT_TRAIN = os.path.join(PROJECT_DIR, \"train_cot_parsing.jsonl\")\n",
        "\n",
        "# quick peek\n",
        "for rec in load_dataset(\"json\", data_files={\"train\": QP_TRAIN})[\"train\"].select(range(2)):\n",
        "    print(\"QP INPUT:\", rec[\"input\"])\n",
        "    print(\"QP OUTPUT:\", rec[\"output\"], \"\\n---\")"
      ],
      "metadata": {
        "id": "UtAj-1ztsJis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Factory"
      ],
      "metadata": {
        "id": "xcJ1WrOmsQQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_lora_model(model_name, max_length):\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name, max_seq_length=max_length, dtype=torch.float16, load_in_4bit=True\n",
        "    )\n",
        "    model = FastLanguageModel.get_peft_model(\n",
        "        model,\n",
        "        r=64, lora_alpha=16, lora_dropout=0.05,\n",
        "        target_modules=[\n",
        "            \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "            \"gate_proj\", \"up_proj\", \"down_proj\"\n",
        "        ],\n",
        "        bias=\"none\", random_state=42, max_seq_length=max_length\n",
        "    )\n",
        "    tokenizer.padding_side = \"right\"\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "Aq7pCEIMsPvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train DeepSeek QP Model"
      ],
      "metadata": {
        "id": "czHV3tuGsVRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load QP dataset\n",
        "ds_qp = load_dataset(\"json\", data_files={\"train\": QP_TRAIN})[\"train\"].shuffle(42)\n",
        "\n",
        "model_name = \"deepseek-ai/deepseek-coder-6.7b-instruct\"\n",
        "MAX_LEN_QP = 1024\n",
        "OUTPUT_QP  = os.path.join(PROJECT_DIR, \"deepseek_adapter_qp_only\")\n",
        "\n",
        "# build model & tokenizer\n",
        "qp_model, qp_tok = make_lora_model(model_name, MAX_LEN_QP)\n",
        "\n",
        "# preprocess fn\n",
        "def preprocess_qp(batch):\n",
        "    inp, out = batch[\"input\"], batch[\"output\"]\n",
        "    full = qp_tok(inp + out, truncation=True, padding=\"max_length\", max_length=MAX_LEN_QP)\n",
        "    prompt_ids = qp_tok(inp, truncation=True, max_length=MAX_LEN_QP)[\"input_ids\"]\n",
        "    labels = full[\"input_ids\"].copy(); labels[:len(prompt_ids)] = [-100]*len(prompt_ids)\n",
        "    full[\"labels\"] = labels\n",
        "    return full\n",
        "\n",
        "qp_tok_ds = ds_qp.map(preprocess_qp, batched=False).with_format(\"torch\")\n",
        "\n",
        "# trainer\n",
        "args_qp = TrainingArguments(\n",
        "    output_dir=OUTPUT_QP, num_train_epochs=12,\n",
        "    per_device_train_batch_size=8, gradient_accumulation_steps=2,\n",
        "    learning_rate=1e-5, warmup_steps=50, lr_scheduler_type=\"cosine\",\n",
        "    fp16=True, save_strategy=\"epoch\", logging_strategy=\"epoch\",\n",
        "    report_to=\"none\", eval_strategy=\"no\"\n",
        ")\n",
        "trainer_qp = Trainer(model=qp_model, args=args_qp, train_dataset=qp_tok_ds, tokenizer=qp_tok)\n",
        "\n",
        "trainer_qp.train()"
      ],
      "metadata": {
        "id": "mlKm4Y9msYrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "ADAPTER_DIR = os.path.join(PROJECT_DIR, \"deepseek_adapter_qp_only\")\n",
        "os.makedirs(ADAPTER_DIR, exist_ok=True)\n",
        "\n",
        "# Save LoRA adapter-only weights + tokenizer\n",
        "qp_model.save_pretrained(ADAPTER_DIR)\n",
        "qp_tok.save_pretrained(ADAPTER_DIR)\n",
        "\n",
        "# Create ZIP archive\n",
        "shutil.make_archive(ADAPTER_DIR, 'zip', ADAPTER_DIR)\n",
        "\n",
        "print(f\"✅ Deepseek QP Adapter-only bundle created at {ADAPTER_DIR}.zip\")"
      ],
      "metadata": {
        "id": "4FwvA71PscnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train DeepSeek CoT Model"
      ],
      "metadata": {
        "id": "KzmcFxEVsykV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now CoT\n",
        "ds_cot = load_dataset(\"json\", data_files={\"train\": COT_TRAIN})[\"train\"].shuffle(42)\n",
        "\n",
        "MAX_LEN_COT = 2048\n",
        "OUTPUT_COT  = os.path.join(PROJECT_DIR, \"deepseek_adapter_cot_only\")\n",
        "\n",
        "cot_model, cot_tok = make_lora_model(model_name, MAX_LEN_COT)\n",
        "\n",
        "def preprocess_cot(batch):\n",
        "    inp, out = batch[\"input\"], batch[\"output\"]\n",
        "    full = cot_tok(inp + out, truncation=True, padding=\"max_length\", max_length=MAX_LEN_COT)\n",
        "    prompt_ids = cot_tok(inp, truncation=True, max_length=MAX_LEN_COT)[\"input_ids\"]\n",
        "    labels = full[\"input_ids\"].copy(); labels[:len(prompt_ids)] = [-100]*len(prompt_ids)\n",
        "    full[\"labels\"] = labels\n",
        "    return full\n",
        "\n",
        "cot_tok_ds = ds_cot.map(preprocess_cot, batched=False).with_format(\"torch\")\n",
        "\n",
        "args_cot = TrainingArguments(\n",
        "    output_dir=OUTPUT_COT, num_train_epochs=12,\n",
        "    per_device_train_batch_size=8, gradient_accumulation_steps=2,\n",
        "    learning_rate=1e-5, warmup_steps=50, lr_scheduler_type=\"cosine\",\n",
        "    fp16=True, save_strategy=\"epoch\", logging_strategy=\"epoch\",\n",
        "    report_to=\"none\", eval_strategy=\"no\"\n",
        ")\n",
        "trainer_cot = Trainer(model=cot_model, args=args_cot, train_dataset=cot_tok_ds, tokenizer=cot_tok)\n",
        "\n",
        "trainer_cot.train()"
      ],
      "metadata": {
        "id": "CiV--7olsyHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save only LoRA adapter and tokenizer\n",
        "ADAPTER_DIR = os.path.join(PROJECT_DIR, \"deepseek_adapter_cot_only\")\n",
        "os.makedirs(ADAPTER_DIR, exist_ok=True)\n",
        "\n",
        "cot_model.save_pretrained(ADAPTER_DIR)\n",
        "cot_tok.save_pretrained(ADAPTER_DIR)\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive(ADAPTER_DIR, 'zip', ADAPTER_DIR)\n",
        "\n",
        "print(f\"✅ Deepseek COT Adapter-only bundle created at {ADAPTER_DIR}.zip\")"
      ],
      "metadata": {
        "id": "8A4Xwikks5tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference and Evaluation"
      ],
      "metadata": {
        "id": "DY5MgcEetEzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# optional JSON5 parser\n",
        "try:\n",
        "    import json5\n",
        "    USE_JSON5 = True\n",
        "except ImportError:\n",
        "    USE_JSON5 = False"
      ],
      "metadata": {
        "id": "xsndGmL4tjOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Templates"
      ],
      "metadata": {
        "id": "bQIvWJ9Btofm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Two-Shot Prompt Templates for ICL\n",
        "\n",
        "# Example 1 (parsing demo):\n",
        "QP_EX1 = '''The question is:\n",
        "\n",
        "There are 6 volunteers: A, B, C, D, E and F. They will be assigned to either Project Alpha or Project Beta. Each person works on exactly one project. This assignment must satisfy:\n",
        "(1) If A works on Alpha, then B works on Beta.\n",
        "(2) If C works on Alpha, then D and E work on Beta.\n",
        "(3) F works on a different project than E.\n",
        "(4) D must work on a different project than A.\n",
        "(5) If F works on Alpha, then B works on Alpha.\n",
        "\n",
        "If A works on Beta, which of the following must be true?\n",
        "A. B works on Alpha\n",
        "B. C works on Beta\n",
        "C. D works on Alpha\n",
        "D. F works on Beta\n",
        "\n",
        "The parsing result is:\n",
        "\n",
        "[\n",
        "  \"There are 6 volunteers: A, B, C, D, E and F. They will be assigned to either Project Alpha or Project Beta. Each person works on exactly one project.\",\n",
        "  \"If A works on Alpha, then B works on Beta\",\n",
        "  \"If C works on Alpha, then D and E work on Beta\",\n",
        "  \"F works on a different project than E\",\n",
        "  \"D must work on a different project than A\",\n",
        "  \"If F works on Alpha, then B works on Alpha\",\n",
        "  \"A works on Beta\"\n",
        "]\n",
        "'''\n",
        "\n",
        "# Example 2\n",
        "QP_EX2 = '''The question is:\n",
        "\n",
        "Five friends—Anna, Ben, Carla, Dan, and Eric—are seated in a row of five chairs. They sit in the order from leftmost (chair 1) to rightmost (chair 5). We know:\n",
        "(1) Anna is somewhere to the left of Dan.\n",
        "(2) Ben is immediately to the right of Carla.\n",
        "(3) Eric occupies either chair 1 or chair 5.\n",
        "(4) Carla is not in chair 3.\n",
        "\n",
        "Who is seated in chair 3?\n",
        "A. Anna\n",
        "B. Ben\n",
        "C. Carla\n",
        "D. Dan\n",
        "E. Eric\n",
        "\n",
        "The parsing result is:\n",
        "\n",
        "[\n",
        "  \"Five friends: Anna, Ben, Carla, Dan, Eric, seated left-to-right in chairs 1–5\",\n",
        "  \"Anna is to the left of Dan\",\n",
        "  \"Ben is immediately to the right of Carla\",\n",
        "  \"Eric is in chair 1 or chair 5\",\n",
        "  \"Carla is not in chair 3\"\n",
        "]\n",
        "'''\n",
        "\n",
        "QP_TEMPLATE = '''Given a question, extract all relevant information from the question that would help to solve it.\n",
        "\n",
        "This includes:\n",
        "- General setup information (e.g., number of people, projects involved)\n",
        "- Explicit facts given in the question\n",
        "- All logical constraints or conditions\n",
        "\n",
        "Output **only** a JSON list and nothing else. Follow the format shown in the examples exactly.\n",
        "\n",
        "Example 1:\n",
        "{ex1}\n",
        "\n",
        "Example 2:\n",
        "{ex2}\n",
        "\n",
        "Now, the question is:\n",
        "\n",
        "{question}\n",
        "\n",
        "Your output MUST be only a JSON array.\n",
        "'''\n",
        "\n",
        "# CoT parsing with two-shot\n",
        "CP_EX1 = '''The question is:\n",
        "\n",
        "There are 6 volunteers: A, B, C, D, E and F. They will be assigned to either Project Alpha or Project Beta. Each person works on exactly one project.\n",
        "\n",
        "Conditions:\n",
        "(1) If A works on Alpha, then B works on Beta.\n",
        "(2) If C works on Alpha, then D and E work on Beta.\n",
        "(3) F works on a different project than E.\n",
        "(4) D must work on a different project than A.\n",
        "(5) If F works on Alpha, then B works on Alpha.\n",
        "\n",
        "Question:\n",
        "If A works on Beta, which of the following must be true?\n",
        "A. B works on Alpha\n",
        "B. C works on Beta\n",
        "C. D works on Alpha\n",
        "D. F works on Beta\n",
        "\n",
        "CoT:\n",
        "Since A works on Beta, Condition (1) is not triggered. Condition (2) is not triggered since C’s assignment is unknown. Condition (3) doesn’t give anything because E’s assignment is unspecified. Condition (4) says D must work on a different project than A, so D must work on Alpha. Condition (5) depends on F, which is unknown.\n",
        "\n",
        "Parsing result:\n",
        "\n",
        "[\n",
        "  {\n",
        "    \"statement\": \"Condition (1) is not applicable\",\n",
        "    \"evidence\": \"Condition (1): If A works on Alpha, then B works on Beta. | A is working on Beta\",\n",
        "    \"Verification\": \"false\"\n",
        "  },\n",
        "  {\n",
        "    \"statement\": \"Condition (2) is not applicable\",\n",
        "    \"evidence\": \"Condition (2): If C works on Alpha, then D and E work on Beta. | C’s assignment is unknown\",\n",
        "    \"Verification\": \"false\"\n",
        "  },\n",
        "  {\n",
        "    \"statement\": \"Condition (3) does not provide any info\",\n",
        "    \"evidence\": \"Condition (3): F works on a different project than E. | E’s assignment is unknown\",\n",
        "    \"Verification\": \"false\"\n",
        "  },\n",
        "  {\n",
        "    \"statement\": \"D must work on Alpha\",\n",
        "    \"evidence\": \"Condition (4): D must work on a different project than A, and A is working on Beta\",\n",
        "    \"Verification\": \"true\"\n",
        "  },\n",
        "  {\n",
        "    \"statement\": \"Condition (5) is not applicable\",\n",
        "    \"evidence\": \"Condition (5): If F works on Alpha, then B works on Alpha. | F’s assignment is unknown\",\n",
        "    \"Verification\": \"false\"\n",
        "  }\n",
        "]\n",
        "'''\n",
        "\n",
        "CP_EX2 = '''The question is:\n",
        "\n",
        "Five friends—Anna, Ben, Carla, Dan, and Eric—are seated in a row of five chairs. They sit in the order from leftmost (chair 1) to rightmost (chair 5). We know:\n",
        "(1) Anna is somewhere to the left of Dan.\n",
        "(2) Ben is immediately to the right of Carla.\n",
        "(3) Eric occupies either chair 1 or chair 5.\n",
        "(4) Carla is not in chair 3.\n",
        "\n",
        "Question:\n",
        "Who is seated in chair 3?\n",
        "A. Anna\n",
        "B. Ben\n",
        "C. Carla\n",
        "D. Dan\n",
        "E. Eric\n",
        "\n",
        "CoT:\n",
        "Since Eric is at one end, he cannot be in chair 3. Carla can’t be in chair 3, so neither Ben (who sits right of Carla) nor Carla occupy it. That leaves Anna or Dan. But Anna must be left of Dan, so only Dan can sit in the middle. Thus chair 3 is Dan.\n",
        "\n",
        "Parsing result:\n",
        "\n",
        "[\n",
        "  {\n",
        "    \"statement\": \"Eric cannot be in chair 3\",\n",
        "    \"evidence\": \"Eric occupies either chair 1 or chair 5\",\n",
        "    \"Verification\": \"true\"\n",
        "  },\n",
        "  {\n",
        "    \"statement\": \"Carla and Ben cannot be in chair 3\",\n",
        "    \"evidence\": \"Carla is not in chair 3\",\n",
        "    \"Verification\": \"true\"\n",
        "  },\n",
        "  {\n",
        "    \"statement\": \"Only Anna or Dan remain for chair 3\",\n",
        "    \"evidence\": \"Eric, Carla, Ben eliminated from chair 3\",\n",
        "    \"Verification\": \"true\"\n",
        "  },\n",
        "  {\n",
        "    \"statement\": \"Dan occupies chair 3\",\n",
        "    \"evidence\": \"Anna must be to the left of Dan, so Dan must be in the middle\",\n",
        "    \"Verification\": \"true\"\n",
        "  }\n",
        "]\n",
        "'''\n",
        "\n",
        "CP_TEMPLATE = '''You are a reasoning assistant. Based on the question, conditions, and chain-of-thought (CoT), extract every inference or non-inference step as a JSON object.\n",
        "\n",
        "For each CoT sentence that either:\n",
        "  1. Refers to a condition (e.g. “Condition (2) …”)\n",
        "  2. Starts with an inference cue (“Since”, “Therefore”, “This means”, “We can deduce”, etc.)\n",
        "\n",
        "Produce **exactly** one JSON object per step with keys:\n",
        "- \"statement\"\n",
        "- \"evidence\"\n",
        "- \"Verification\" (\"true\" or \"false\")\n",
        "\n",
        "Output **only** a JSON array. Follow the examples exactly.\n",
        "\n",
        "Example 1:\n",
        "{ex1}\n",
        "\n",
        "Example 2:\n",
        "{ex2}\n",
        "\n",
        "Now, given:\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Conditions:\n",
        "{conditions}\n",
        "\n",
        "Chain-of-Thought:\n",
        "{cot}\n",
        "\n",
        "Your output MUST be only a JSON array.\n",
        "'''"
      ],
      "metadata": {
        "id": "yLc1yvxttlYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "BQ69qj-ptxqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def clean_quotes(text):\n",
        "    return text.replace('“','\"').replace('”','\"').replace(\"‘\",\"'\").replace(\"’\",\"'\")\n",
        "\n",
        "def normalize_question_text(text):\n",
        "    t = clean_quotes(text)\n",
        "    t = re.sub(r'\\?\\s(?=[A-Z])', ', ', t)\n",
        "    t = re.sub(r'(?<=[a-zA-Z])\\.(?=[A-Z])', '. ', t)\n",
        "    t = re.sub(r'(?<![A-Da-d])\\\\n(?!\\s?[A-Da-d]\\\\.)', ' ', t)\n",
        "    return html.unescape(t).strip()\n",
        "\n",
        "def extract_first_json_array(raw: str):\n",
        "    raw = raw.strip()\n",
        "    start = raw.find('[')\n",
        "    if start < 0: return None\n",
        "    depth = 0\n",
        "    for i, ch in enumerate(raw[start:], start):\n",
        "        if ch == '[': depth += 1\n",
        "        elif ch == ']': depth -= 1\n",
        "        if depth == 0:\n",
        "            block = raw[start:i+1]\n",
        "            for parser in (json.loads, ast.literal_eval, (json5.loads if USE_JSON5 else None)):\n",
        "                if not parser: continue\n",
        "                try: return parser(block)\n",
        "                except: pass\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "def safe_extract_qp(raw):\n",
        "    return extract_first_json_array(raw) or []\n",
        "\n",
        "def safe_extract_cp(raw):\n",
        "    arr = extract_first_json_array(raw) or []\n",
        "    normalized = []\n",
        "    for entry in arr:\n",
        "        if isinstance(entry, dict):\n",
        "            normalized.append(entry)\n",
        "        elif isinstance(entry, str):\n",
        "            normalized.append({\n",
        "                \"statement\": entry.strip(),\n",
        "                \"evidence\": \"logical deduction\",\n",
        "                \"Verification\": \"true\"\n",
        "            })\n",
        "    return normalized"
      ],
      "metadata": {
        "id": "ecapMj8_trZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load DeepSeek models"
      ],
      "metadata": {
        "id": "tNEt2fnFt1qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# quant config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True\n",
        ")\n",
        "\n",
        "# QP pipeline\n",
        "qp_tok = AutoTokenizer.from_pretrained(\n",
        "    \"/content/drive/MyDrive/llm-sr-project/deepseek_adapter_qp_only\"\n",
        ")\n",
        "qp_tok.padding_side    = \"left\"\n",
        "qp_tok.truncation_side = \"right\"\n",
        "qp_tok.model_max_length= 1024\n",
        "\n",
        "qp_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"/content/drive/MyDrive/llm-sr-project/deepseek_adapter_qp_only\",\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "qp_pipe = pipeline(\n",
        "    \"text-generation\", model=qp_model, tokenizer=qp_tok,\n",
        "    return_full_text=False, num_beams=1, do_sample=False\n",
        ")\n",
        "print(\"✅ QP model loaded\")\n",
        "\n",
        "# CoT pipeline\n",
        "cot_tok = AutoTokenizer.from_pretrained(\n",
        "    \"/content/drive/MyDrive/llm-sr-project/deepseek_adapter_cot_only\"\n",
        ")\n",
        "cot_tok.padding_side    = \"left\"\n",
        "cot_tok.truncation_side = \"right\"\n",
        "cot_tok.model_max_length= 2048\n",
        "\n",
        "cot_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"/content/drive/MyDrive/llm-sr-project/deepseek_adapter_cot_only\",\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "cot_pipe = pipeline(\n",
        "    \"text-generation\", model=cot_model, tokenizer=cot_tok,\n",
        "    return_full_text=False, num_beams=1, do_sample=False\n",
        ")\n",
        "print(\"✅ CoT model loaded\")"
      ],
      "metadata": {
        "id": "Kvh3d2Hft1Kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Test Data"
      ],
      "metadata": {
        "id": "_YSQDhmjt7aN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_path = \"/content/drive/MyDrive/llm-sr-project/testingData-blank.json\"\n",
        "with open(input_path, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# build QP prompts\n",
        "qp_prompts = [\n",
        "    QP_TEMPLATE.format(\n",
        "        ex1=QP_EX1, ex2=QP_EX2,\n",
        "        question=normalize_question_text(item[\"question\"])\n",
        "    )\n",
        "    for item in data\n",
        "]\n",
        "print(f\"Built {len(qp_prompts)} QP prompts\")"
      ],
      "metadata": {
        "id": "oimavXR3t_bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Batch QP and CoT Parsing"
      ],
      "metadata": {
        "id": "hhTuDp6uuBIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qp_outs = qp_pipe(qp_prompts, max_new_tokens=512, batch_size=4)\n",
        "qp_raws = [\n",
        "    (o[0][\"generated_text\"] if isinstance(o, list) else o[\"generated_text\"])\n",
        "    for o in qp_outs\n",
        "]\n",
        "\n",
        "# extract constraints\n",
        "qp_lists = []\n",
        "for raw in qp_raws:\n",
        "    qp_lists.append(safe_extract_qp(raw))\n",
        "print(f\"→ Extracted QP constraints for {len(qp_lists)} examples\")\n",
        "\n",
        "# prepare CoT prompts\n",
        "cp_prompts = []\n",
        "for item, constraints in zip(data, qp_lists):\n",
        "    q   = normalize_question_text(item[\"question\"])\n",
        "    cot = normalize_question_text(item[\"cot\"])\n",
        "    cond_json = json.dumps(constraints, ensure_ascii=False)\n",
        "    cp_prompts.append(\n",
        "        CP_TEMPLATE.format(\n",
        "            ex1=CP_EX1, ex2=CP_EX2,\n",
        "            question=q, conditions=cond_json, cot=cot\n",
        "        )\n",
        "    )\n",
        "\n",
        "# run\n",
        "cp_outs = cot_pipe(cp_prompts, max_new_tokens=1024, batch_size=4)\n",
        "cp_raws = [\n",
        "    (o[0][\"generated_text\"] if isinstance(o, list) else o[\"generated_text\"])\n",
        "    for o in cp_outs\n",
        "]\n",
        "\n",
        "# normalize steps\n",
        "all_results = []\n",
        "for constraints, raw in zip(qp_lists, cp_raws):\n",
        "    steps = safe_extract_cp(raw)\n",
        "    # dedupe & filter\n",
        "    clean = []\n",
        "    seen = set()\n",
        "    for st in steps:\n",
        "        s = st.get(\"statement\",\"\").strip()\n",
        "        e = st.get(\"evidence\",\"\").strip() or \"logical deduction\"\n",
        "        v = str(st.get(\"Verification\",\"true\")).lower()\n",
        "        if len(s)>=5 and (s,e) not in seen:\n",
        "            seen.add((s,e))\n",
        "            clean.append({\"statement\":s,\"evidence\":e,\"Verification\":v})\n",
        "    all_results.append(clean)\n",
        "\n",
        "print(f\"→ Parsed CoT steps for {len(all_results)} examples\")"
      ],
      "metadata": {
        "id": "RSgK8H7ruHZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Predictions"
      ],
      "metadata": {
        "id": "DbTPoH7vuMgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# combine and save\n",
        "output_path = \"/content/drive/MyDrive/llm-sr-project/testingDataresultsforVerifier.json\"\n",
        "results = []\n",
        "for item, qp_res, cot_res in zip(data, qp_lists, all_results):\n",
        "    results.append({\n",
        "        \"question\":         item[\"question\"],\n",
        "        \"question_parsing\": qp_res,\n",
        "        \"answer\":           item.get(\"answer\"),\n",
        "        \"id\":               item[\"id\"],\n",
        "        \"cot\":              item[\"cot\"],\n",
        "        \"cot_parsing\":      cot_res,\n",
        "        \"sel_idx\":          item[\"id\"],\n",
        "    })\n",
        "\n",
        "with open(output_path, \"w\") as f:\n",
        "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "print(\"✅ Saved inference to\", output_path)"
      ],
      "metadata": {
        "id": "6GGHt4mkuO5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ],
      "metadata": {
        "id": "YjrKXSYkuRGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EVAL_SCRIPT = \"/content/drive/MyDrive/llm-sr-project/eval.py\"\n",
        "PREDICTION_PATH = \"/content/drive/MyDrive/llm-sr-project/testingDataresultsforVerifier.json\"\n",
        "REFERENCE_PATH = \"/content/drive/MyDrive/llm-sr-project/test-reference.json\"\n",
        "\n",
        "!python {EVAL_SCRIPT} \\\n",
        "  --prediction {PREDICTION_PATH} \\\n",
        "  --reference {REFERENCE_PATH} \\\n",
        "  --question_threshold 0.95 \\\n",
        "  --statement_threshold 0.9 \\\n",
        "  --relation_threshold 0.9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REF4yxBjuTH9",
        "outputId": "06b24486-957b-4445-ea9d-d7ba18bb4e2c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-17 14:51:23.991515: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-17 14:51:24.008633: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747493484.029676    4210 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747493484.036039    4210 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-17 14:51:24.057176: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "config.json: 100% 1.05k/1.05k [00:00<00:00, 8.39MB/s]\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "model.safetensors: 100% 738M/738M [00:02<00:00, 269MB/s]\n",
            "tokenizer_config.json: 100% 1.28k/1.28k [00:00<00:00, 11.3MB/s]\n",
            "spm.model: 100% 2.46M/2.46M [00:00<00:00, 31.8MB/s]\n",
            "tokenizer.json: 100% 8.66M/8.66M [00:00<00:00, 9.36MB/s]\n",
            "added_tokens.json: 100% 23.0/23.0 [00:00<00:00, 239kB/s]\n",
            "special_tokens_map.json: 100% 286/286 [00:00<00:00, 3.21MB/s]\n",
            "\u001b[?25lTotal number of predictions: \u001b[1;36m24\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0mAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  4%\u001b[0m \u001b[36m-:--:--\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  8%\u001b[0m \u001b[36m0:00:32\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 12%\u001b[0m \u001b[36m0:01:28\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 17%\u001b[0m \u001b[36m0:01:05\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 21%\u001b[0m \u001b[36m0:00:59\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 25%\u001b[0m \u001b[36m0:00:50\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 29%\u001b[0m \u001b[36m0:00:44\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 33%\u001b[0m \u001b[36m0:00:41\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 38%\u001b[0m \u001b[36m0:00:35\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 42%\u001b[0m \u001b[36m0:00:33\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 46%\u001b[0m \u001b[36m0:00:28\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 50%\u001b[0m \u001b[36m0:00:25\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 54%\u001b[0m \u001b[36m0:00:23\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 58%\u001b[0m \u001b[36m0:00:20\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[35m 62%\u001b[0m \u001b[36m0:00:18\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[35m 67%\u001b[0m \u001b[36m0:00:16\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[35m 71%\u001b[0m \u001b[36m0:00:13\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[35m 75%\u001b[0m \u001b[36m0:00:11\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[35m 79%\u001b[0m \u001b[36m0:00:09\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[35m 83%\u001b[0m \u001b[36m0:00:07\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[35m 88%\u001b[0m \u001b[36m0:00:06\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 92%\u001b[0m \u001b[36m0:00:04\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 96%\u001b[0m \u001b[36m0:00:02\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[3m           Evaluation Results           \u001b[0m\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
            "┃\u001b[35m \u001b[0m\u001b[35mMetric                     \u001b[0m\u001b[35m \u001b[0m┃\u001b[35m \u001b[0m\u001b[35mValue \u001b[0m\u001b[35m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
            "│ Question_Macro_F1           │ 0.476  │\n",
            "│ Statement_Macro_F1          │ 0.1157 │\n",
            "│ Statement_Evidence_Macro_F1 │ 0.0445 │\n",
            "│ Reasoning_F1                │ 0.0362 │\n",
            "└─────────────────────────────┴────────┘\n",
            "Question_Macro_F1: 0.476\n",
            "Statement_Macro_F1: 0.1157\n",
            "Statement_Evidence_Macro_F1: 0.0445\n",
            "Reasoning_F1: 0.0362\n"
          ]
        }
      ]
    }
  ]
}