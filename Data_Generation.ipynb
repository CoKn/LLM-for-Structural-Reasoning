{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Synthetic Data Generation with Gpt",
   "id": "ebaeedf11805ed18"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-02T14:51:36.947656Z",
     "start_time": "2025-06-02T14:51:35.971694Z"
    }
   },
   "source": [
    "import os\n",
    "from utils.AzureAdapter import AzureAdapter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"AZURE_API_KEY\")\n",
    "api_endpoint = os.getenv(\"AZURE_API_ENDPOINT\")\n",
    "api_version = os.getenv(\"AZURE_API_VERSION\")\n",
    "deployment_name = \"gpt-4o\"\n",
    "\n",
    "llm = AzureAdapter(api_key=api_key, api_endpoint=api_endpoint, api_version=api_version)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:51:36.960097Z",
     "start_time": "2025-06-02T14:51:36.954117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import time\n",
    "from random import randint\n",
    "from utils.save_json import save_json\n",
    "\n",
    "def parse_and_save(llm_response, folder_path=\"\", save_data=True):\n",
    "    seed = int(time.time())\n",
    "\n",
    "    # Parse the response from the llm\n",
    "    data = json.loads(llm_response)\n",
    "\n",
    "    # Add sel_idx and id\n",
    "    if type(data) == dict and 'puzzles' in data.keys():\n",
    "        data = data['puzzles']\n",
    "\n",
    "    if type(data) == dict:\n",
    "        data = [data]\n",
    "\n",
    "    # Save each puzzle as own json\n",
    "    for puzzle in data:\n",
    "        rand =  randint(0, 1000000)\n",
    "        puzzle['id'] = rand\n",
    "        puzzle['sel_idx'] = rand\n",
    "        if save_data:\n",
    "            save_json(data=puzzle, file_path=f'{folder_path}/{seed}_{rand}.json')\n",
    "\n",
    "    print((type(data), len(data)))\n",
    "    return data"
   ],
   "id": "85cc18c9c1c1f7c4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Generating puzzles with one llm call",
   "id": "bb335258a96e709d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:26:30.245412Z",
     "start_time": "2025-06-02T14:26:21.338073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from prompts.prompts import entire_puzzle_generation_prompt\n",
    "\n",
    "prompt = 'Generate generate 10 new puzzles'\n",
    "res = llm.call_model(prompt=prompt, system_prompt=entire_puzzle_generation_prompt, deployment_name=deployment_name)"
   ],
   "id": "fb85557da2051766",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:27:10.525935Z",
     "start_time": "2025-06-02T14:27:10.522017Z"
    }
   },
   "cell_type": "code",
   "source": "data = parse_and_save(folder_path='./data/synthetic/gpt_one_call', llm_response=res)",
   "id": "bceeef2f553d913",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'list'>, 1)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Creating Puzzles in two llm calls",
   "id": "b1678ffc89fbddd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T14:52:04.970725Z",
     "start_time": "2025-06-02T14:51:43.558893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from prompts.prompts import question_generation_prompt, solution_generation_prompt\n",
    "\n",
    "# Create puzzle questions\n",
    "prompt_questions = \"Generate generate 10 new puzzle questions\"\n",
    "res_questions = llm.call_model(prompt=prompt_questions, system_prompt=question_generation_prompt, deployment_name=deployment_name)\n",
    "questions = parse_and_save(llm_response=res_questions, save_data=False)\n",
    "\n",
    "prompt_solutions = \"Solve the following logical puzzles:\\n {}\".format(questions)\n",
    "res_solutions = llm.call_model(prompt=prompt_solutions, system_prompt=solution_generation_prompt, deployment_name=deployment_name)\n",
    "solutions = parse_and_save(folder_path='./data/synthetic/gpt_two_calls', llm_response=res_solutions, save_data=True)"
   ],
   "id": "38c726a826ebc414",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'list'>, 1)\n",
      "(<class 'list'>, 1)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Puzzle verification\n",
    "\n",
    "##### Duplicates\n",
    "Often LLMs generate redundant puzzle so we need to filter out redundant puzzles. Here we can use two different approaches.\n",
    "1. We can use a LLM as classifier to assess based on the semantics if there are duplicates\n",
    "2. We can use a syntactic assessment via a the levenstein distance"
   ],
   "id": "3ed222dcc6056fc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e0f5f86d4af2e6a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Quality",
   "id": "d9e08b7b6b9e13cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "69ecf539e49068c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-nlp-project",
   "language": "python",
   "name": ".venv-nlp-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
