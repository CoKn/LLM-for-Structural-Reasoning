{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1_rlLRyy8MhMAl85Amae4XaPkYoqZDRX1","authorship_tag":"ABX9TyMc5w1jniyXjN4Oenf/o984"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 7. Reward-Model-Based Selection for CoT Parsing\n","\n","In this approach we:\n","\n","1. **Generate 5 CoT parsing candidates** (2 beam, 3 sampled)  \n","2. **Score each step** with `OpenAssistant/reward-model-deberta-v3-large-v2`  \n","3. **Add evidence bonuses** for condition references, logical connectors, etc.  \n","4. **Average per-step scores** and pick the highest-scoring candidate  \n","\n","This prioritizes logical soundness and strong evidence. Results are saved to  \n","`final_results_reward_model.json` for downstream F1 evaluation.\n"],"metadata":{"id":"8icHVBsj2zB3"}},{"cell_type":"markdown","source":["## Imports and Setup"],"metadata":{"id":"28xE0bGo27lv"}},{"cell_type":"code","source":["# Install core evaluation utilities\n","!pip install -q evaluate\n","!pip install json5\n","\n","!pip uninstall -y nltk\n","!pip install -q --upgrade nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y_Zn6ZWd3EOy","executionInfo":{"status":"ok","timestamp":1747496171288,"user_tz":-120,"elapsed":9958,"user":{"displayName":"Erlisa Lokaj","userId":"15715708909238941246"}},"outputId":"7b0ed438-920b-4003-9c89-311e9f82e1e6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting json5\n","  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n","Downloading json5-0.12.0-py3-none-any.whl (36 kB)\n","Installing collected packages: json5\n","Successfully installed json5-0.12.0\n","Found existing installation: nltk 3.9.1\n","Uninstalling nltk-3.9.1:\n","  Successfully uninstalled nltk-3.9.1\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download(\"punkt_tab\")\n","nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w7tcsWkG3E0C","executionInfo":{"status":"ok","timestamp":1747496186512,"user_tz":-120,"elapsed":2315,"user":{"displayName":"Erlisa Lokaj","userId":"15715708909238941246"}},"outputId":"08237623-7c04-42a9-9d24-0a26863d7757"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["import gc, json, re, ast, html, numpy as np\n","import torch\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForCausalLM,\n","    AutoModelForSequenceClassification,\n","    pipeline\n",")\n","from datasets import load_dataset\n","\n","# cleanup\n","torch.cuda.empty_cache()\n","gc.collect()\n","\n","try:\n","    import json5\n","    USE_JSON5 = True\n","except ImportError:\n","    USE_JSON5 = False\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"metadata":{"id":"vi0Ln27j261P","executionInfo":{"status":"ok","timestamp":1747496209531,"user_tz":-120,"elapsed":16902,"user":{"displayName":"Erlisa Lokaj","userId":"15715708909238941246"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Paths\n","INPUT       = \"/content/drive/MyDrive/llm-sr-project/testingData-blank.json\"\n","OUTPUT      = \"/content/drive/MyDrive/llm-sr-project/results_reward_model.json\"\n","QP_LM_PATH  = \"/content/drive/MyDrive/llm-sr-project/finetuned_llama3_question_parsing\"\n","CP_LM_PATH  = \"/content/drive/MyDrive/llm-sr-project/finetuned_llama3_cot_parsing\"\n","REWARD_MODEL_PATH = \"OpenAssistant/reward-model-deberta-v3-large-v2\"\n","\n","# Configuration\n","NUM_CANDIDATES = 5  # Generate multiple CP candidates\n","GENERATION_DIVERSITY = 0.85  # Higher diversity in generation"],"metadata":{"id":"yoU0Ed4u3qPn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prompt Templates and Helper Functions"],"metadata":{"id":"KWQbK9QH3Gx0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"E_bTWWD32S-w"},"outputs":[],"source":["# In-Context Learning (ICL) Prompts\n","\n","QP_DEMON = '''The question is:\n","\n","There are 6 volunteers: A, B, C, D, E and F. They will be assigned to either Project Alpha or Project Beta. Each person works on exactly one project. This assignment must satisfy:\n","(1) If A works on Alpha, then B works on Beta.\n","(2) If C works on Alpha, then D and E work on Beta.\n","(3) F works on a different project than E.\n","(4) D must work on a different project than A.\n","(5) If F works on Alpha, then B works on Alpha.\n","\n","If A works on Beta, which of the following must be true?\n","A. B works on Alpha\n","B. C works on Beta\n","C. D works on Alpha\n","D. F works on Beta\n","\n","The parsing result is:\n","\n","[\n","  \"There are 6 volunteers: A, B, C, D, E and F. They will be assigned to either Project Alpha or Project Beta. Each person works on exactly one project.\",\n","  \"If A works on Alpha, then B works on Beta\",\n","  \"If C works on Alpha, then D and E work on Beta\",\n","  \"F works on a different project than E\",\n","  \"D must work on a different project than A\",\n","  \"If F works on Alpha, then B works on Alpha\",\n","  \"A works on Beta\"\n","]\n","'''\n","\n","QP_TEMPLATE = '''Given a question, extract all relevant information from the question that would help to solve it.\n","\n","This includes:\n","- General setup information (e.g., number of people, projects involved)\n","- Explicit facts given in the question\n","- All logical constraints or conditions\n","\n","Output only a JSON list and nothing else. Follow the format shown in the example.\n","\n","Example:\n","\n","{demon}\n","\n","Now, the question is:\n","\n","{question}\n","\n","Your output:\n","'''\n","\n","CP_DEMON = '''The question is:\n","\n","There are 6 volunteers: A, B, C, D, E and F. Each person works on exactly one project.\n","\n","Conditions:\n","(1) If A works on Alpha, then B works on Beta.\n","(2) If C works on Alpha, then D and E work on Beta.\n","(3) F works on a different project than E.\n","(4) D must work on a different project than A.\n","(5) If F works on Alpha, then B works on Alpha.\n","\n","Question:\n","If A works on Beta, which of the following must be true?\n","\n","CoT:\n","Since A works on Beta, Condition (1) is not triggered. Condition (2) is not triggered since C's assignment is unknown. Condition (3) doesn't give anything because E's assignment is unspecified. Condition (4) says D must work on a different project than A, so D must work on Alpha. Condition (5) depends on F, which is unknown.\n","\n","Parsing result:\n","\n","[\n","  {\n","    \"statement\": \"Condition (1) is not applicable\",\n","    \"evidence\": \"Condition (1): If A works on Alpha, then B works on Beta. | A is working on Beta\",\n","    \"Verification\": \"false\"\n","  },\n","  {\n","    \"statement\": \"Condition (2) is not applicable\",\n","    \"evidence\": \"Condition (2): If C works on Alpha, then D and E work on Beta. | C's assignment is unknown\",\n","    \"Verification\": \"false\"\n","  },\n","  {\n","    \"statement\": \"Condition (3) does not provide any info\",\n","    \"evidence\": \"Condition (3): F works on a different project than E. | E's assignment is unknown\",\n","    \"Verification\": \"false\"\n","  },\n","  {\n","    \"statement\": \"D must work on Alpha\",\n","    \"evidence\": \"Condition (4): D must work on a different project than A, and A is working on Beta\",\n","    \"Verification\": \"true\"\n","  },\n","  {\n","    \"statement\": \"Condition (5) is not applicable\",\n","    \"evidence\": \"Condition (5): If F works on Alpha, then B works on Alpha. | F's assignment is unknown\",\n","    \"Verification\": \"false\"\n","  }\n","]\n","'''\n","\n","CP_TEMPLATE = '''You are a reasoning assistant. Based on the question, conditions, and chain-of-thought (CoT), extract every inference or non-inference step as a JSON object.\n","\n","For each CoT sentence that either:\n","  1. Refers to a condition (e.g. \"Condition (2) …\")\n","  2. Starts with an inference cue (\"Since\", \"Therefore\", \"This means\", \"We can deduce\", etc.)\n","\n","Produce one object with:\n","  • \"statement\": the new claim you read in that CoT sentence (don't quote the entire sentence—just the core inference).\n","  • \"evidence\":\n","      – if the claim restates a constraint, use the exact line from the **Conditions** block,\n","      – otherwise, use the CoT fragment that you extracted it from.\n","  • \"Verification\":\n","      – `\"false\"` if the sentence rejects or blocks a condition (contains \"not applicable\", \"does not provide\", etc.),\n","      – otherwise `\"true\"`.\n","\n","Keep the objects in the same order as they appear in the CoT.\n","\n","Example:\n","\n","{demon}\n","\n","Now, given:\n","\n","Question:\n","{question}\n","\n","Conditions:\n","{conditions}\n","\n","Chain-of-Thought:\n","{cot}\n","\n","Your output:\n","'''\n","\n","\n","REWARD_PROMPT = '''I need you to evaluate the quality of a reasoning step in a logical inference task.\n","\n","Given the following context:\n","\n","Question:\n","{question}\n","\n","Conditions:\n","{conditions}\n","\n","Chain of Thought:\n","{cot}\n","\n","Evaluate the following reasoning step:\n","Statement: {statement}\n","Evidence: {evidence}\n","\n","Rate the quality of this reasoning step on a scale from 1 to 10 where:\n","1-3: Low quality (unclear, incorrect, or unsupported)\n","4-6: Medium quality (partially correct or somewhat supported)\n","7-10: High quality (clear, correct, and well-supported by evidence)\n","\n","Focus on:\n","1. Is the statement logically supported by the evidence?\n","2. Is the evidence clearly derived from the conditions or chain of thought?\n","3. Does the reasoning step contribute meaningfully to solving the problem?\n","\n","Your rating (1-10):\n","'''"]},{"cell_type":"code","source":["# Helper Functions\n","def clean_quotes(t):\n","    return (t.replace('\"','\"').replace('\"','\"').replace(\"'\",\"'\").replace(\"'\",\"'\"))\n","\n","def normalize_text(t):\n","    t = clean_quotes(t)\n","    t = re.sub(r'\\?\\s(?=[A-Z])', ', ', t)\n","    t = re.sub(r'(?<=[a-zA-Z])\\.(?=[A-Z])', '. ', t)\n","    t = re.sub(r'(?<![A-Da-d])\\\\n(?!\\s?[A-Da-d]\\\\.)', ' ', t)\n","    return html.unescape(t).strip()\n","\n","def extract_json(raw):\n","    raw = raw.strip()\n","    i = raw.find('[')\n","    if i < 0: return []\n","    depth = 0\n","    for j,ch in enumerate(raw[i:], i):\n","        if ch=='[': depth+=1\n","        elif ch==']': depth-=1\n","        if depth==0:\n","            blk = raw[i:j+1]\n","            # Try different parsers\n","            for p in [json.loads, ast.literal_eval, (json5.loads if USE_JSON5 else None)]:\n","                if p:\n","                    try: return p(blk)\n","                    except: pass\n","            return []\n","    return []\n","\n","def clean_qp(qp_list):\n","    return [s for s in qp_list if not re.match(r'^[A-Da-d][\\.:\\)]', s.strip()) and \"Option\" not in s and \"following\" not in s]\n","\n","def extract_rating(text):\n","    \"\"\"Extract numerical rating from reward model output\"\"\"\n","    # Try to find a number in the text\n","    matches = re.findall(r'\\b([1-9]|10)\\b', text)\n","    if matches:\n","        return int(matches[0])\n","    else:\n","        # Fallback - check for keywords\n","        if any(word in text.lower() for word in [\"excellent\", \"outstanding\", \"great\", \"high quality\"]):\n","            return 9\n","        elif any(word in text.lower() for word in [\"good\", \"well\", \"solid\"]):\n","            return 7\n","        elif any(word in text.lower() for word in [\"average\", \"adequate\", \"fair\"]):\n","            return 5\n","        elif any(word in text.lower() for word in [\"poor\", \"weak\", \"bad\"]):\n","            return 3\n","        else:\n","            return 5  # Default middle score"],"metadata":{"id":"6lSmuU2-3RT3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load Models"],"metadata":{"id":"LML3iPc63Y2U"}},{"cell_type":"code","source":["qp_tok = AutoTokenizer.from_pretrained(QP_LM_PATH)\n","qp_tok.model_max_length = 1024\n","qp_mod = AutoModelForCausalLM.from_pretrained(QP_LM_PATH).to(device)\n","qp_pipe = pipeline(\"text-generation\",\n","                   model=qp_mod,\n","                   tokenizer=qp_tok,\n","                   return_full_text=False,\n","                   do_sample=False,\n","                   num_beams=5,\n","                   early_stopping=True,\n","                   max_new_tokens=512,\n","                   batch_size=4)\n","\n","cp_tok = AutoTokenizer.from_pretrained(CP_LM_PATH)\n","cp_tok.model_max_length = 2048\n","cp_mod = AutoModelForCausalLM.from_pretrained(CP_LM_PATH).to(device)\n","\n","# Main candidate generation - beam search\n","cp_pipe = pipeline(\"text-generation\",\n","                   model=cp_mod,\n","                   tokenizer=cp_tok,\n","                   return_full_text=False,\n","                   do_sample=False,\n","                   num_beams=4,\n","                   num_return_sequences=2,\n","                   early_stopping=True,\n","                   max_new_tokens=1024,\n","                   batch_size=4)\n","\n","# Diverse candidate generation - sampling\n","cp_sampler = pipeline(\"text-generation\",\n","                      model=cp_mod,\n","                      tokenizer=cp_tok,\n","                      return_full_text=False,\n","                      do_sample=True,\n","                      temperature=GENERATION_DIVERSITY,\n","                      top_p=0.92,\n","                      num_return_sequences=3,\n","                      max_new_tokens=1024,\n","                      batch_size=4)\n","\n","# Load the reward model\n","print(f\"Loading reward model from {REWARD_MODEL_PATH}...\")\n","reward_tok = AutoTokenizer.from_pretrained(REWARD_MODEL_PATH)\n","reward_mod = AutoModelForSequenceClassification.from_pretrained(\n","    REWARD_MODEL_PATH,\n","    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n","    device_map=\"auto\"\n",")"],"metadata":{"id":"tmxCU2pr3bzn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Reward Function"],"metadata":{"id":"Sn64Dhc33jLP"}},{"cell_type":"code","source":["# Improved scoring function for OpenAssistant reward model\n","def score_with_reward_model(statement, evidence, question, conditions, cot):\n","    \"\"\"Score a statement-evidence pair using the OpenAssistant reward model with evidence emphasis\"\"\"\n","    # Base scoring from reward model\n","    prompt = f\"Question: {question}\\n\\nConditions: {'; '.join(conditions)}\\n\\nReasoning: {cot}\\n\\nEvaluate:\\nStatement: {statement}\\nEvidence: {evidence}\"\n","    answer = f\"This reasoning step is clear and logically sound. The statement follows directly from the evidence and contributes to solving the problem.\"\n","\n","    # Use the reward model to score the reasoning\n","    inputs = reward_tok(prompt, answer, return_tensors='pt')\n","    inputs = {k: v.to(reward_mod.device) for k, v in inputs.items()}\n","\n","    # Get score from the model\n","    with torch.no_grad():\n","        score = reward_mod(**inputs).logits[0].cpu().item()\n","\n","    # Basic normalization\n","    base_score = min(10, max(1, (score + 5) * 1.0))\n","\n","    # Add evidence quality bonuses (critical for Statement_Evidence_Macro_F1)\n","    evidence_bonus = 0\n","\n","    # Bonus for specific condition references\n","    if any(f\"Condition ({i})\" in evidence for i in range(1, 10)):\n","        evidence_bonus += 2.5\n","\n","    # Bonus for direct quotes from conditions list\n","    for condition in conditions:\n","        condition_text = str(condition).strip().lower()\n","        if len(condition_text) > 10 and condition_text in evidence.lower():\n","            evidence_bonus += 2.0\n","            break\n","\n","    # Bonus for logical structure indicators\n","    if any(term in evidence.lower() for term in [\"therefore\", \"because\", \"implies\", \"since\"]):\n","        evidence_bonus += 1.0\n","\n","    # Penalty for vague evidence\n","    if evidence.lower() in [\"logical deduction\", \"deduction\", \"reasoning\"]:\n","        evidence_bonus -= 2.0\n","\n","    # Calculate final score with emphasis on evidence quality\n","    final_score = min(10, base_score + evidence_bonus)\n","\n","    return final_score"],"metadata":{"id":"n5-wNvYP4LNQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Inference Function"],"metadata":{"id":"ZLaHSx0k4MHh"}},{"cell_type":"code","source":["def process_one(example):\n","    q_raw, cot_raw = example[\"question\"], example[\"cot\"]\n","    sel_idx, ans = example.get(\"sel_idx\"), example.get(\"answer\")\n","    q, cot = normalize_text(q_raw), normalize_text(cot_raw)\n","\n","    # QP generation\n","    prompt = QP_TEMPLATE.format(demon=QP_DEMON, question=q)\n","    raw_qp = qp_pipe(prompt, max_new_tokens=512)\n","    if not isinstance(raw_qp, list):\n","        raw_qp = [raw_qp]\n","    best_qp = clean_qp(extract_json(raw_qp[0][\"generated_text\"]))\n","\n","    # Generate multiple CP candidates for reward-based selection\n","    conds_str = json.dumps(best_qp, ensure_ascii=False)\n","    prompt_cp = CP_TEMPLATE.format(\n","        demon      = CP_DEMON,\n","        question   = q,\n","        conditions = conds_str,\n","        cot        = cot\n","    )\n","\n","    # Generate diverse candidates\n","    raw_beams = cp_pipe(prompt_cp, max_new_tokens=1024)\n","    raw_samples = cp_sampler(prompt_cp, max_new_tokens=1024)\n","\n","    # Combine all candidates\n","    raw_cp_outs = (raw_beams if isinstance(raw_beams, list) else [raw_beams]) \\\n","            + (raw_samples if isinstance(raw_samples, list) else [raw_samples])\n","\n","    # Extract and clean the outputs\n","    cp_candidates = []\n","    for out in raw_cp_outs:\n","        parsed = extract_json(out[\"generated_text\"])\n","        if not parsed:\n","            continue\n","\n","        seen = set()\n","        cleaned = []\n","        for st in parsed:\n","            # Skip malformed entries\n","            if not isinstance(st, dict):\n","                continue\n","\n","            stmt = st.get(\"statement\", \"\")\n","            stmt = stmt.strip() if stmt is not None else \"\"\n","            ev = st.get(\"evidence\", \"\")\n","            ev = ev.strip() if ev is not None else \"\"\n","            ev = ev or \"logical deduction\"\n","            ver  = st.get(\"Verification\",\"true\")\n","\n","            # Normalize verification\n","            if ver not in [\"true\", \"false\"]:\n","                if any(phrase in stmt.lower() for phrase in [\"not applicable\", \"doesn't apply\", \"not triggered\", \"no information\"]):\n","                    ver = \"false\"\n","                else:\n","                    ver = \"true\"\n","\n","            # Skip duplicates and very short statements\n","            if len(stmt) < 3 or (stmt,ev) in seen:\n","                continue\n","\n","            seen.add((stmt,ev))\n","            cleaned.append({\n","                \"statement\": stmt,\n","                \"evidence\": ev,\n","                \"Verification\": ver\n","            })\n","\n","        if cleaned:\n","            cp_candidates.append(cleaned)\n","\n","    # If no valid candidates were found, return empty list\n","    if not cp_candidates:\n","        return {\n","            \"question\": q_raw,\n","            \"question_parsing\": best_qp,\n","            \"answer\": ans,\n","            \"id\": example[\"id\"],\n","            \"cot\": cot_raw,\n","            \"cot_parsing\": [],\n","            \"sel_idx\": sel_idx\n","        }\n","\n","    # Score each candidate's statements with the reward model\n","    print(f\"Scoring {len(cp_candidates)} candidates with reward model...\")\n","    candidate_scores = []\n","    for candidate in cp_candidates:\n","        # Score each statement-evidence pair in the candidate\n","        step_scores = []\n","        for step in candidate:\n","            score = score_with_reward_model(\n","                step[\"statement\"],\n","                step[\"evidence\"],\n","                q, best_qp, cot\n","            )\n","            step_scores.append(score)\n","\n","        # Average score for the candidate\n","        avg_score = sum(step_scores) / len(step_scores) if step_scores else 0\n","        candidate_scores.append(avg_score)\n","\n","    # Select the best candidate based on reward model scores\n","    if candidate_scores:\n","        best_idx = np.argmax(candidate_scores)\n","        best_cp = cp_candidates[best_idx]\n","        print(f\"Selected candidate {best_idx} with score {candidate_scores[best_idx]}\")\n","    else:\n","        # Fallback to first candidate if scoring failed\n","        best_cp = cp_candidates[0]\n","\n","\n","    if best_cp:\n","        # Apply evidence quality post-processing\n","        for step in best_cp:\n","            # Improve evidence quality by making explicit links to conditions\n","            evidence = step[\"evidence\"]\n","            statement = step[\"statement\"]\n","\n","            # Try to fix evidence that lacks specific condition references\n","            if not any(f\"Condition ({i})\" in evidence for i in range(1, 10)):\n","                for i, condition in enumerate(best_qp, 1):\n","                    # If the statement clearly relates to a condition, add explicit reference\n","                    if any(keyword in condition.lower() and keyword in statement.lower()\n","                           for keyword in [\"must\", \"works\", \"assigned\", \"different\", \"project\", \"Alpha\", \"Beta\"]):\n","                        step[\"evidence\"] = f\"Condition ({i}): {condition}. {evidence}\"\n","                        break\n","\n","    return {\n","        \"question\": q_raw,\n","        \"question_parsing\": best_qp,\n","        \"answer\": ans,\n","        \"id\": example[\"id\"],\n","        \"cot\": cot_raw,\n","        \"cot_parsing\": best_cp,\n","        \"sel_idx\": sel_idx\n","    }"],"metadata":{"id":"oosQcSja4VeK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Batch Inference and Save"],"metadata":{"id":"CNwTHEMu4WNn"}},{"cell_type":"code","source":["def process_batch(batch):\n","    # Process one example at a time due to reward model complexity\n","    outs = [process_one({\n","        \"question\": batch[\"question\"][i],\n","        \"cot\":       batch[\"cot\"][i],\n","        \"id\":        batch[\"id\"][i],\n","        \"sel_idx\":   batch.get(\"sel_idx\", [None]*len(batch[\"id\"]))[i],\n","        \"answer\":    batch.get(\"answer\", [None]*len(batch[\"id\"]))[i],\n","    }) for i in range(len(batch[\"question\"]))]\n","\n","    return {\n","        \"question\":        [o[\"question\"]        for o in outs],\n","        \"question_parsing\":[o[\"question_parsing\"]for o in outs],\n","        \"answer\":          [o[\"answer\"]          for o in outs],\n","        \"id\":              [o[\"id\"]              for o in outs],\n","        \"cot\":             [o[\"cot\"]             for o in outs],\n","        \"cot_parsing\":     [o[\"cot_parsing\"]     for o in outs],\n","        \"sel_idx\":         [o[\"sel_idx\"]         for o in outs],\n","    }\n","\n","if __name__==\"__main__\":\n","    gc.collect()\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    print(f\"Using device: {device}\")\n","\n","    try:\n","        ds = load_dataset(\"json\", data_files={\"test\": INPUT})[\"test\"]\n","        print(f\"Loaded dataset with {len(ds)} examples\")\n","\n","        print(f\"Starting processing with enhanced OpenAssistant reward model...\")\n","        print(f\"Generating {NUM_CANDIDATES} candidates per example with diversity {GENERATION_DIVERSITY}\")\n","\n","        # Process with smaller batch size due to reward model overhead\n","        out_ds = ds.map(\n","            process_batch,\n","            batched=True,\n","            batch_size=1,\n","            remove_columns=ds.column_names\n","        )\n","\n","        print(f\"Processing complete. Writing results to {OUTPUT}\")\n","        out_ds.to_json(OUTPUT, orient=\"records\", lines=False)\n","        print(\"✅ Done — saved to\", OUTPUT)\n","    except Exception as e:\n","        print(f\"Error occurred: {type(e).__name__}: {e}\")\n","        import traceback\n","        traceback.print_exc()"],"metadata":{"id":"ZnkUy2g74b-v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Structure file for evaluation"],"metadata":{"id":"-kOVakSf4eVC"}},{"cell_type":"code","source":["import json\n","\n","INPUT_PATH  = \"/content/drive/MyDrive/llm-sr-project/results_reward_model.json\"\n","OUTPUT_PATH =\"/content/drive/MyDrive/llm-sr-project/final_results_reward_model.json\"\n","\n","def transform_example(ex):\n","    # reorder each cot_parsing entry: statement → evidence → Verification\n","    reordered = []\n","    for step in ex.get(\"cot_parsing\", []):\n","        reordered.append({\n","            \"statement\":    step.get(\"statement\"),\n","            \"evidence\":     step.get(\"evidence\"),\n","            \"Verification\": step.get(\"Verification\"),\n","        })\n","\n","    return {\n","        \"question\":         ex.get(\"question\"),\n","        \"question_parsing\": ex.get(\"question_parsing\"),\n","        \"answer\":           ex.get(\"answer\"),\n","        \"id\":               ex.get(\"id\"),\n","        \"cot\":              ex.get(\"cot\"),\n","        \"cot_parsing\":      reordered,\n","        \"sel_idx\":          ex.get(\"sel_idx\"),\n","    }\n","\n","def main():\n","    with open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n","        examples = json.load(f)\n","\n","    structured = [transform_example(ex) for ex in examples]\n","\n","    with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(structured, f, ensure_ascii=False, indent=2)\n","\n","    print(f\"Wrote {len(structured)} examples to {OUTPUT_PATH}\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"zcr-m7lt4l5P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluate"],"metadata":{"id":"Uhbeycdw4msv"}},{"cell_type":"code","source":["EVAL_SCRIPT = \"/content/drive/MyDrive/llm-sr-project/eval.py\"\n","PREDICTION_PATH = \"/content/drive/MyDrive/llm-sr-project/final_results_reward_model.json\"\n","REFERENCE_PATH = \"/content/drive/MyDrive/llm-sr-project/test-reference.json\"\n","\n","!python {EVAL_SCRIPT} \\\n","  --prediction {PREDICTION_PATH} \\\n","  --reference {REFERENCE_PATH} \\\n","  --question_threshold 0.95 \\\n","  --statement_threshold 0.9 \\\n","  --relation_threshold 0.9"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RmjcSzZY4oeA","executionInfo":{"status":"ok","timestamp":1747496294804,"user_tz":-120,"elapsed":80648,"user":{"displayName":"Erlisa Lokaj","userId":"15715708909238941246"}},"outputId":"c6fc0f01-2e32-477b-de1a-243ff3d8bda6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["2025-05-17 15:36:59.777196: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1747496219.798135    3253 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1747496219.804458    3253 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","config.json: 100% 1.05k/1.05k [00:00<00:00, 8.20MB/s]\n","Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","model.safetensors: 100% 738M/738M [00:04<00:00, 148MB/s]\n","tokenizer_config.json: 100% 1.28k/1.28k [00:00<00:00, 9.99MB/s]\n","spm.model: 100% 2.46M/2.46M [00:00<00:00, 33.4MB/s]\n","tokenizer.json: 100% 8.66M/8.66M [00:00<00:00, 14.9MB/s]\n","added_tokens.json: 100% 23.0/23.0 [00:00<00:00, 223kB/s]\n","special_tokens_map.json: 100% 286/286 [00:00<00:00, 2.67MB/s]\n","\u001b[?25lTotal number of predictions: \u001b[1;36m24\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0mAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  4%\u001b[0m \u001b[36m-:--:--\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  8%\u001b[0m \u001b[36m0:00:49\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 12%\u001b[0m \u001b[36m0:01:09\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 17%\u001b[0m \u001b[36m0:00:59\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 21%\u001b[0m \u001b[36m0:00:54\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 25%\u001b[0m \u001b[36m0:00:46\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 29%\u001b[0m \u001b[36m0:00:40\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 33%\u001b[0m \u001b[36m0:00:40\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 38%\u001b[0m \u001b[36m0:00:39\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 42%\u001b[0m \u001b[36m0:00:38\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 46%\u001b[0m \u001b[36m0:00:34\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 50%\u001b[0m \u001b[36m0:00:32\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 54%\u001b[0m \u001b[36m0:00:28\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 58%\u001b[0m \u001b[36m0:00:25\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[35m 62%\u001b[0m \u001b[36m0:00:21\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[35m 67%\u001b[0m \u001b[36m0:00:18\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[35m 71%\u001b[0m \u001b[36m0:00:16\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[35m 75%\u001b[0m \u001b[36m0:00:13\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[35m 79%\u001b[0m \u001b[36m0:00:11\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[35m 83%\u001b[0m \u001b[36m0:00:10\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[35m 88%\u001b[0m \u001b[36m0:00:07\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[35m 92%\u001b[0m \u001b[36m0:00:05\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[35m 96%\u001b[0m \u001b[36m0:00:03\u001b[0m\u001b[92m────────────────────────────────────────────────────────────────────────────────\u001b[0m\n","\u001b[2K\u001b[36m Evaluating ...\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[3m           Evaluation Results           \u001b[0m\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n","┃\u001b[35m \u001b[0m\u001b[35mMetric                     \u001b[0m\u001b[35m \u001b[0m┃\u001b[35m \u001b[0m\u001b[35mValue \u001b[0m\u001b[35m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n","│ Question_Macro_F1           │ 0.7658 │\n","│ Statement_Macro_F1          │ 0.366  │\n","│ Statement_Evidence_Macro_F1 │ 0.1041 │\n","│ Reasoning_F1                │ 0.0439 │\n","└─────────────────────────────┴────────┘\n","Question_Macro_F1: 0.7658\n","Statement_Macro_F1: 0.366\n","Statement_Evidence_Macro_F1: 0.1041\n","Reasoning_F1: 0.0439\n"]}]}]}