{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Transformation and Finetuning with OpenPipe",
   "id": "6538db123adabdb0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-03T17:43:44.016778Z",
     "start_time": "2025-06-03T17:43:42.262124Z"
    }
   },
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "from argon2.low_level import error_to_str\n",
    "from openpipe import OpenAI\n",
    "from prompts.prompts import qp_system_prompt, cp_system_prompt, qp_system_prompt_sudoku, cp_system_prompt_sudoku\n",
    "from utils.save_and_load_json import load_all_json_files, save_jsonl, save_json\n",
    "from utils.transfrom_data_for_finetuing import split_dataset, format_qp_for_openpipe_finetuning, format_cp_for_openpipe_finetuning\n",
    "\n",
    "# load in datasets\n",
    "logic701 = load_all_json_files(folder_path='./data/train/raw')\n",
    "gpt_one_call = load_all_json_files(folder_path='./data/synthetic/processed/gpt_one_call')\n",
    "gpt_two_calls = load_all_json_files(folder_path='./data/synthetic/processed/gpt_two_calls')\n",
    "sudoku = load_all_json_files(folder_path='./data/synthetic/processed/sudoku_4x4')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 JSON files from ./data/train/raw\n",
      "Loaded 1 JSON files from ./data/synthetic/processed/gpt_one_call\n",
      "Loaded 1 JSON files from ./data/synthetic/processed/gpt_two_calls\n",
      "Loaded 1 JSON files from ./data/synthetic/processed/sudoku_4x4\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:43:44.038116Z",
     "start_time": "2025-06-03T17:43:44.026776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Get 250 random samples\n",
    "logic701_samples = random.sample(logic701[0], 250)\n",
    "sudoku_samples = random.sample(sudoku[0], 250)\n",
    "gpt_one_call_samples = random.sample(gpt_one_call[0], 250)\n",
    "gpt_two_call_samples = random.sample(gpt_two_calls[0], 250)\n",
    "\n",
    "print('verifying dataset len samples:')\n",
    "print(len(logic701_samples))\n",
    "print(len(sudoku_samples))\n",
    "print(len(gpt_one_call_samples))\n",
    "print(len(gpt_two_call_samples))\n",
    "\n",
    "# create qp and cp splits\n",
    "logic701_samples_qp, logic701_samples_cp = split_dataset(logic701_samples)\n",
    "sudoku_samples_qp, sudoku_samples_cp = split_dataset(sudoku_samples)\n",
    "gpt_one_call_samples_qp, gpt_one_call_samples_cp = split_dataset(gpt_one_call_samples)\n",
    "gpt_two_call_samples_qp, gpt_two_call_samples_cp = split_dataset(gpt_two_call_samples)\n",
    "\n",
    "print('verifying dataset len for qp and cp:')\n",
    "for dataset in [logic701_samples_qp, logic701_samples_cp, sudoku_samples_qp, sudoku_samples_cp, gpt_one_call_samples_qp, gpt_two_call_samples_qp, gpt_two_call_samples_cp]: print(len(dataset))"
   ],
   "id": "bbdb9f7e733c1636",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verifying dataset len samples:\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "verifying dataset len for qp and cp:\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:43:44.922309Z",
     "start_time": "2025-06-03T17:43:44.824606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# format data into OpenAI finetuning format for OpenPipe\n",
    "logic701_formatted_qp = format_qp_for_openpipe_finetuning(logic701_samples_qp, system_prompt=qp_system_prompt)\n",
    "logic701_formatted_cp = format_cp_for_openpipe_finetuning(logic701_samples_cp, system_prompt=cp_system_prompt)\n",
    "\n",
    "sudoku_formatted_qp = format_qp_for_openpipe_finetuning(sudoku_samples_qp, system_prompt=qp_system_prompt)\n",
    "sudoku_formatted_cp = format_cp_for_openpipe_finetuning(sudoku_samples_cp, system_prompt=cp_system_prompt)\n",
    "\n",
    "gpt_one_call_formatted_qp = format_qp_for_openpipe_finetuning(gpt_one_call_samples_qp, system_prompt=qp_system_prompt)\n",
    "gpt_one_call_formatted_cp = format_cp_for_openpipe_finetuning(gpt_one_call_samples_cp, system_prompt=cp_system_prompt)\n",
    "\n",
    "gpt_two_call_formatted_qp = format_qp_for_openpipe_finetuning(gpt_two_call_samples_qp, system_prompt=qp_system_prompt)\n",
    "gpt_two_call_formatted_cp = format_cp_for_openpipe_finetuning(gpt_two_call_samples_cp, system_prompt=cp_system_prompt)\n",
    "\n",
    "# save data as jsonl\n",
    "save_jsonl(logic701_formatted_qp, \"./data/synthetic/finetuning/logic701_finetuning_qp.jsonl\")\n",
    "save_jsonl(logic701_formatted_cp, \"./data/synthetic/finetuning/logic701_finetuning_cp.jsonl\")\n",
    "\n",
    "save_jsonl(sudoku_formatted_qp, \"./data/synthetic/finetuning/sudoku_finetuning_qp.jsonl\")\n",
    "save_jsonl(sudoku_formatted_cp, \"./data/synthetic/finetuning/sudoku_finetuning_cp.jsonl\")\n",
    "\n",
    "save_jsonl(gpt_one_call_formatted_qp, \"./data/synthetic/finetuning/gpt_one_call_finetuning_qp.jsonl\")\n",
    "save_jsonl(gpt_one_call_formatted_cp, \"./data/synthetic/finetuning/gpt_one_call_finetuning_cp.jsonl\")\n",
    "\n",
    "save_jsonl(gpt_two_call_formatted_qp, \"./data/synthetic/finetuning/gpt_two_call_finetuning_qp.jsonl\")\n",
    "save_jsonl(gpt_two_call_formatted_cp, \"./data/synthetic/finetuning/gpt_two_call_finetuning_cp.jsonl\")"
   ],
   "id": "5aaa7dbd01f592b7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:43:46.744802Z",
     "start_time": "2025-06-03T17:43:46.488828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from openpipe import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load api key\n",
    "load_dotenv()\n",
    "open_pipe = os.getenv(\"structural-reasoning\")\n",
    "\n",
    "client = OpenAI(openpipe={\"api_key\": f\"{open_pipe}\"})"
   ],
   "id": "1132f7ff3b17a5aa",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:43:47.401216Z",
     "start_time": "2025-06-03T17:43:47.393424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load test data\n",
    "with open('./data/test/test-reference.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_qp, test_cp = split_dataset(test_data)"
   ],
   "id": "c1f5e2cb9d635298",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:43:48.962498Z",
     "start_time": "2025-06-03T17:43:48.952839Z"
    }
   },
   "cell_type": "code",
   "source": "test_cp[0]",
   "id": "59bab6bf62c318ae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'b',\n",
       " 'id': 162,\n",
       " 'cot': \"Since G goes to the United States, we need to analyze the conditions that follow. Condition (1) is not applicable since G is going to the US. Condition (2) is also not applicable since L's destination is not specified. Condition (3) does not provide any information about H, M, U, or W. Condition (4) states that U's destination is different from G's, which is the US, so U must go to the UK. Condition (5) is not applicable since Z's destination is not specified.\",\n",
       " 'cot_parsing': [{'statement': 'Condition (1) is not applicable',\n",
       "   'evidence': 'Condition (1): If G goes to the UK, then H To the United States. | G is going to the US',\n",
       "   'Verification': 'false'},\n",
       "  {'statement': 'Condition (2) is also not applicable',\n",
       "   'evidence': \"Condition (2): If L goes to the UK, both M and U go to the US. | L's destination is not specified\",\n",
       "   'Verification': 'false'},\n",
       "  {'statement': 'Condition (3) does not provide any information about H, M, U, or W',\n",
       "   'evidence': 'Condition (3): The country W went to was different from the country Z went to.',\n",
       "   'Verification': 'false'},\n",
       "  {'statement': 'U must go to the UK',\n",
       "   'evidence': \"Condition (4): The country where U goes is different from the country where G goes. | Condition (4) states that U's destination is different from G's, which is the US\",\n",
       "   'Verification': 'true'},\n",
       "  {'statement': 'Condition (5) is not applicable',\n",
       "   'evidence': \"Condition (5): If Z goes to the UK, then H also goes to the UK. | Z's destination is not specified\",\n",
       "   'Verification': 'true'}],\n",
       " 'sel_idx': 92}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:43:51.259341Z",
     "start_time": "2025-06-03T17:43:51.251305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run inference pipeline\n",
    "# Format question data\n",
    "content_formated_question = format_qp_for_openpipe_finetuning(test_qp, system_prompt=qp_system_prompt)\n",
    "content_questions = [item[\"messages\"][1][\"content\"] for item in content_formated_question]\n",
    "\n",
    "# Format CoT data\n",
    "content_formated_cot = format_cp_for_openpipe_finetuning(test_cp, system_prompt=cp_system_prompt)\n",
    "content_cots = [item[\"messages\"][1][\"content\"] for item in content_formated_cot]"
   ],
   "id": "b94450c569ea7bad",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:57:28.933686Z",
     "start_time": "2025-06-03T17:57:28.910640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_pipeline(test_qp, test_cp, content_question,  content_cot, model_qp, model_cp):\n",
    "    puzzle = {\n",
    "            \"question\": test_qp['question'],\n",
    "            \"question_parsing\": None,\n",
    "            \"answer\": test_cp['answer'],\n",
    "            \"id\": test_cp['id'],\n",
    "            \"sel_idx\": test_cp['sel_idx'],\n",
    "            \"cot\": test_cp['cot'],\n",
    "            \"cot_parsing\": None\n",
    "                }\n",
    "\n",
    "    try:\n",
    "        completion_qp = client.chat.completions.create(\n",
    "            model=model_qp,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": qp_system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": content_question\n",
    "                }\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        string_data = completion_qp.choices[0].message.content.replace('\\'', '\"')\n",
    "        print(string_data)\n",
    "        puzzle[\"question_parsing\"] = json.loads(string_data)\n",
    "\n",
    "        completion_cp = client.chat.completions.create(\n",
    "            model=model_cp,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": cp_system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": content_cot\n",
    "                }\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        print(completion_cp.choices[0].message.content)\n",
    "        puzzle[\"cot_parsing\"] = json.loads(completion_cp.choices[0].message.content)\n",
    "        return puzzle\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return None, None"
   ],
   "id": "f3cdc075b534181",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:20:58.762164Z",
     "start_time": "2025-06-03T18:20:57.113188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "name = 'sudoku'  # 'logic701', gpt_one_call, gpt_two_calls, sudoku\n",
    "results = []\n",
    "error_n = 0\n",
    "errors = []\n",
    "for idx in range(len(test_data)):\n",
    "    try:\n",
    "        result = run_pipeline(test_qp[idx],\n",
    "                              test_cp[idx],\n",
    "                              content_question=content_questions[idx],\n",
    "                              content_cot=content_cots[idx],\n",
    "                              model_qp='openpipe:sudoku-finetuning-qp',\n",
    "                              model_cp='openpipe:sudoku-finetuning-cp')\n",
    "        results.append(result)\n",
    "        break\n",
    "        # print(result)\n",
    "        save_json(result, \"./data/comparison/sudoku/result-{}-{}.json\".format(idx, name))\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e} at index {idx}\")\n",
    "        error_n += 1\n",
    "        errors.append(idx)"
   ],
   "id": "b08af93da0785111",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"question_parsing\": \"The puzzle has the rows: [\"G, H, L, M, U, W, Z\"]\\nThe puzzle has the columns: [\"G, H, L, M, U, W, Z\"]\\nThe puzzle has the squares: [\" GHLM\", \" UZW\"]\"}\n",
      "Error occurred: Expecting ',' delimiter: line 1 column 50 (char 49)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:20:41.764554Z",
     "start_time": "2025-06-03T18:18:51.321388Z"
    }
   },
   "cell_type": "code",
   "source": "print(error_n)",
   "id": "7095b0587e38fe59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:19:05.572726Z",
     "start_time": "2025-06-03T18:19:05.519588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_combined = load_all_json_files(folder_path='./data/comparison/gpt_two_call')\n",
    "save_json(data_combined, \"./data/comparison/gpt_two_call-combined.json\")"
   ],
   "id": "4a1509504440fef7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 JSON files from ./data/comparison/gpt_two_call\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T16:12:59.640337Z",
     "start_time": "2025-06-03T16:12:59.636433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lines = string_data.split('\\n')\n",
    "string_data = completion.choices[0].message.content.replace('\\'', '\"')\n",
    "\n",
    "json.loads(string_data)"
   ],
   "id": "da68e5b92c638fb1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2a22d902f2f58144"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-nlp-project",
   "language": "python",
   "name": ".venv-nlp-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
